# Profiling and Tracing Support for Java Applications

## 摘要

> We demonstrate the ==feasibility== of undertaking performance evaluations for JVMs using: (1) a hybrid JVM/OS tool, such as async-profiler, (2) OS centric profiling and tracing tools based on Linux perf, and (3) the *Extended Berkeley Packet Filter Tracing* (eBPF) framework where we demonstrate the rationale behind the standard offwaketime tool, for analysing the causes of blocking latencies, and our own eBPF-based tool bcc-java, that relates changes in microarchitecture performance counter values to the execution of individual JVM and application threads at low overhead.
>
> The relative execution time overheads of the performance tools are illustrated for the DaCapo-bach-9.12 benchmarks with OpenJDK9 on an Intel Xeon E5-2690, running Ubuntu 16.04. Whereas sampling based tools can have up to 25% slowdown using 4kHz frequency, our tool bcc-java has a geometric mean of less than 5%. Only for the avrora benchmark, bcc-java has a significant overhead (37%) due to an unusually high number of futex system calls. <u>Finally, we provide a discussion on the recommended approaches to solve specific performance use-case scenarios.</u>
>

我们证明了使用以下方法对 JVM 进行性能评估的==可行性==：(1) 混合的 JVM/OS 工具，例如 *async-profiler*，(2) 基于 Linux perf 的以操作系统为中心的分析和跟踪工具，以及 (3) 我们展示了 *eBPF* 框架中标准 `offwaketime` 工具背后的基本原理，用于分析为何会阻塞，以及我们自己基于 *eBPF* 的工具 **bcc-java**，该工具以较低的成本将微体系结构性能计数器值的变化与单个 JVM 和应用程序线程的执行联系起来。

性能工具相对执行时间的开销在运行 Ubuntu 16.04 的英特尔至强 E5-2690 上使用 OpenJDK9 的 DaCapo-bach-9.12 基准测试进行说明。使用 4kHz 频率时，基于采样的工具性能可能会降低 25%，而我们的工具 `bcc-java` 引入的开销的几何平均值小于 5%。只是对于 avrora 基准测试，由于 `futex` 系统调用数量特别多，**bcc-java** 具有显著的开销（37%）。<u>最后，我们讨论了解决特定性能用例场景的推荐方法</u>。

## 1   简介

> We briefly survey standard performance evaluation approaches and tools, and their limitations for Java Virtual Machines (JVMs) concerning *Garbage Collection* (GC) log files, heap analysis, lock contention, processor core sampling, and ==bytecode based instrumentation== for the measurement of application specific performance metrics (Table [1 ](#_bookmark5)summarises tool features and capabilities). Logging involves turning on JVM flags to monitor specific JVM subsystem behavior (e.g. JIT compilation or GC). The two main approaches to profiling are tracing and sampling. ==Tracing instruments code== to measure microarchitecture or system performance metrics. Sampling profilers repeatedly collect the stack trace of called functions/methods, that describe the code running on the processing core, *on-core*, at the sampled moments in time.
>
> The Unix OS perf tool is becoming widely used as it supports both **sampling** and **tracing**. In the Java community, sampling based profiling is widely implemented with *JVM Tools Interface* (JVMTI) agent support using GetCallTrace (e.g. JProfiler). This approach is reliant on restricting sampling to safe-points, that are inserted by the JIT compiler to support GC. Such restrictions generate bias, and can lead to incorrect performance information. DTrace was a key tool popularizing tracing on Solaris, and then ported to FreeBSD, NetBSD, Mac OS, and in 2018 to Windows. Since 2016, Linux integrated similar functionality via the eBPF framework (Kernel version 4.9). This paper demonstrate the feasibility of undertaking performance evaluations for unmodified JVMs using either, (1), a hybrid JVM/OS tool, such as async-profiler, (2), OS-centric profiling and tracing tools based on perf, or (3) our own eBPF-based tracing tool, bcc-java. The contributions of this paper are:
>
> - We measure the overheads of on-core sampling with profiling for 100Hz (1 sample every 10ms), 1kHz (every 1ms) and 4kHz (every 250*µ*s) for the DaCapo benchmarks. We find that 1kHz sampling can be used with the `async-profiler` and `perf`/`perf-map-agent` with a reasonable geomean overhead of less than 5.2% and 11.2% respectively compared to normal execution.
> - We show how flamegraphs produced using `perf` combined with `perf-map-agent` can be used to identify where JIT based compilation has failed to inline successfully.
> - We report that heap allocation based profiling using the `async-profiler` is low overhead, at less than 2.8%, for all benchmarks, and that flamegraphs enable developers to easily determine the main allocation sources in their programs.
> - We present a low overhead tracing tool `bcc-java` (see Section [5)](#_bookmark11) with a geometric mean overhead of 3.6% for characterizing the performance of all service and application threads created by a JVM. The `bcc-java` tool is developed on top of Linux *eBPF Compiler Collection* (BCC) [[12](#_bookmark21), [23](#_bookmark38)] for adding tracing support to operating system kernels and applications. Performance counter measurements such as instructions executed, processor cycles and cache misses can be directly related to application thread IDs, and to VM services. The monitoring techniques in the tool have generic applicability that could be deployed to characterize any multi-threaded application.
> - We demonstrate how the BCC `offwaketime` tracing tool can be used to produce flamegraph visualizations that describe ==important aspects== of thread blocking and wakeup execution behavior without requiring JVM modifications.
> - We summarize the main features of the tools async-profiler, perf, offwaketime, and our new bcc-java tool in Table [1.](#_bookmark5)
>
> Section [2 ](#_bookmark0)generally discusses the capabilities of log file analysis tools targeting GC and JVM related memory performance analysis. Section [3 ](#_bookmark1)presents Flamegraphs [[13\] ](#_bookmark22)and how to interpret them for JVMs. Section [4 ](#_bookmark4)explains the capabilities of traditional Java based profiling tools and their limitations. The benefits of `AsyncGetCallTrace` based profiling, and the *stack fragment sampling* approach of [[15\] ](#_bookmark25)are discussed. Section [5 ](#_bookmark11)explains the rationale behind the design of the eBPF/BCC tools and the tracing tool that we have built. Section [6 ](#_bookmark12)presents our experimental methodology and performance overhead analysis. Section [7 ](#_bookmark13)presents guidelines for the use of performance evaluation tools under different use-cases, and finally Section [8 ](#_bookmark23)discusses our conclusions.
>

我们简要调研了评估 Java 虚拟机 (JVM) 性能的标准方法和工具，以及它们对 JVM 的限制，涉及 **GC** 日志文件、堆分析、锁争用、处理器采样和==基于字节码的工具==，用于测量特定于应用程序的性能指标（表 [1](#_bookmark5) 总结了这些工具的特性和功能）。日志涉及打开  JVM 标志以监视特定的 JVM 子系统行为（例如 JIT 编译或 GC）。主要的两种分析方法是跟踪和抽样。==跟踪工具代码==以**测量微体系结构**或**系统性能指标**。采样分析器反复收集被调用函数/方法的堆栈，这些函数/方法描述了在采样时刻在处理核心 *on-core* 上运行的代码。

因为支持**采样**和**跟踪**，Unix OS perf 工具正在得到广泛使用。在 Java 社区中，基于采样的分析器（例如 JProfiler）主要通过 **JVM 工具接口代理 (JVMTI)** 利用 `GetCallTrace` 来实现。这种方法依赖于将采样限制在安全点，这些安全点由 JIT 编译器插入以支持 GC。此类限制会产生偏差，并可能导致不正确的性能信息。`DTrace` 是在 Solaris 上关键的主流跟踪工具，然后移植到 FreeBSD、NetBSD、Mac OS，并于 2018 年移植到 Windows。自 2016 年以来，Linux 通过 eBPF 框架（内核版本 4.9）集成了类似的功能。本文展示了使用以下任一方法对未修改的 JVM 进行性能评估的可行性：(1) 混合 JVM/OS 工具，例如 async-profiler，(2) 基于 perf 的以操作系统为中心的分析和跟踪工具，或 (3 ) 我们自己的基于 eBPF 的跟踪工具 bcc-java。 本文的贡献是：

- 对于 [DaCapo 基准测试](https://www.cs.utexas.edu/users/mckinley/papers/dacapo-oopsla-2006.pdf)，通过 100Hz（每 10ms 1 个样本）、1kHz（每 1ms）和 4kHz（每 250*µ*s）的分析来测量 CPU 采样的开销。发现 `async-profiler` 和 `perf/perf-map-agent` 可以按 1kHz 采样，与正常执行相比，合理的几何平均开销分别小于 5.2% 和 11.2%。
- 展示如何使用 `perf` 结合 `perf-map-agent` 生成的火焰图用于识别 JIT 编译器未能成功内联的代码。
- 使用 `async-profiler` 进行基于堆分配的分析开销很低，所有基准测试的开销都低于 2.8%，并且火焰图使开发人员能够轻松确定代码中分配内存的主要源头。
- 提供了一个低开销跟踪工具`bcc-java`（参见[第 5 节](#_bookmark11)），其几何平均开销为 3.6%，用于描述由 JVM 创建的所有服务和应用程序线程的性能。`bcc-java` 工具是在 Linux *eBPF Compiler Collection* (BCC) [[12](#_bookmark21), [23](#_bookmark38)] （它们支持向操作系统内核和应用程序添加跟踪）之上开发的。<u>执行的指令</u>、<u>处理器周期</u>和<u>缓存未命中</u>等性能计数器测量可以与应用程序线程 ID 和 VM 服务直接相关。该工具中的监控技术具有通用性，可用于描述任意的多线程应用程序。
- 演示了如何使用 BCC `offwaketime` 跟踪工具生成可视化的火焰图，用来描述线程阻塞和唤醒执行行为的==重要方面==，无需修改 JVM。
- 在表 [1](#_bookmark5) 中总结了工具 `async-profiler`、`perf`、`offwaketime` 和新的 `bcc-java` 工具的主要特性。

第 [2](#_bookmark0) 节简单描述了<u>**日志文件分析工具**</u>针对 GC 和 JVM 相关内存性能分析的功能。第 [3](#_bookmark1) 节介绍了火焰图 [[13](#_bookmark22)] 以及如何基于 JVM  解释它们。第 [4](#_bookmark4) 节解释了 Java 传统分析工具的功能及其局限性，讨论了基于 `AsyncGetCallTrace` 的好处，以及**堆栈片段采样**法[[15](#_bookmark25)] 。第 [5](#_bookmark11) 节解释了设计 eBPF/BCC 工具和我们构建的跟踪工具背后的基本原理。第 [6](#_bookmark12) 节介绍了我们的实验方法和性能开销分析。第 [7](#_bookmark13) 节介绍了在不同用例下使用性能评估工具的指南，最后 [8](#_bookmark23) 节是我们的结论。

## 2   RELATED WORK: GC & JVM ANALYSIS

JVM implementations support the logging of GC statistics by statically or dynamically turning on JVM flags. The statistics typically concern object allocations, usage of heap memory spaces, *stop-the-world* (STW) pauses, and total execution times for each GC invocation. STW pauses occur when all application threads are blocked during GC. Post-processing or runtime analysis of logs can be performed by tools such as [[10, ](#_bookmark19)[9, ](#_bookmark18)[11, ](#_bookmark20)[20\]. ](#_bookmark31)Lengauer *et al*. [[17\]](#_bookmark27) presents an in-depth analysis of the GC behavior of Java benchmarks including DaCapo using G1 GC in the HotSpot JVM. Automated processing of logs can aid identification and solution of GC related performance problems, such as increasing the maximum heap size, changing the ratio of younger to older generation heap sizes, and changing heuristics for moving objects into different heap spaces. Dynamic dashboard visualizations are typically used to present information concerning the relative health and efficiency of applications in production environments.

However, GC log analysis cannot help in identifying or resolving which application code is the cause of high memory allocation and/or leaks. The JVM can provide a heap dump snapshot of the current live objects at relatively high cost. Such dumps may help developers to determine why GC execution and pause times might be higher than expected. Unfortunately heap dumps lack information on the allocation site of an object, nor can a dump help determine which thread allocated an object. Object deallocations can only be detected by comparing two subsequent dumps and finding that an object was removed. This is difficult as objects often change their heap storage location during GC where objects move between memory generation regions, and in heap compaction. Object allocation profiling and recording of every object using standard JVMs are typically based on expensive [[24\] ](#_bookmark39)combinations of bytecode based instrumentation, and stack traces. Consequently, many tools only record allocations above minimum sizes, and/or every n-th allocation in order to reduce overhead.

AntTracks [[16\] ](#_bookmark26)is a customized HotSpot based JVM that instruments object allocation, movement and deallocation with a low logging overhead of less than 4.68%. The recorded events are sufficiently detailed to enable the heap’s state to be reconstructed offline, for the beginning and end of every GC cycle by incrementally applying the effect of events described in trace files. *Thread local allocation buffers* (TLABs) are used to store event traces, with data compression to minimise trace collection and storage overheads.

Cao *et al*. [[6\] ](#_bookmark15)evaluated the power and performance requirements of managed runtime workload execution. Their work considered single-ISA heterogeneous *asymmetric multicore processor* (AMP) hardware with processor cores that are optimised for different power-performance tradeoffs. The main findings of interest are that GC accounts for 10% of processor execution cycles on average, and nearly 40% for lusearch from the DaCapo benchmarks.

Sartor *et al*. [[21\] ](#_bookmark32)presented techniques to analyze the scalability of managed language applications with speedup stacks. Lightweight OS kernel modules were used to monitor an application and its VM service threads scheduling behavior with an overhead of up to 1.15% but, typically under 1%. They perform experiments on one node of an Intel Xeon E5-2650L server consisting of 2 sockets, each with 20MB shared LLC, 8 physical cores, with hyper threading enabled giving 16 logical cores on each socket, and a 64-bit 3.2.37 Linux kernel. Sufficient logical cores are present to ensure that the OS does not need to schedule out a thread other than for synchronization or I/O. A problem with this approach is that it is not expected to be portable across processor ISA architectures, and it may require recompilation for each new kernel release. For their experiments, they used JikesRVM [[4\] ](#_bookmark35)with the DaCapo lusearch, pmd, sunflow and xalan benchmarks. JikesRVM was modified to record the JVM application, compilation and garbage collection thread type *process identifiers* (PIDs) to enable their kernel modules to attribute microarchitectural performance counter measurements to specific JVM thread types. The *speedup stack* visualization helps developers to determine if optimization efforts that focus on application, or JVM runtime services are likely to improve performance. Our bcc-java tool development was motivated by [[21](#_bookmark32)].

Hofer *et al*. [[14\] ](#_bookmark24)modified OpenJDK8u45 to observe and trace events related to lock contention with a mean runtime overhead of 7.8%. The call-stacks of a thread blocking on a lock, and the thread holding the lock causing the blocking were recorded. They also presented a tool for users to identify locking bottlenecks in their code by analysing the traced events. They identified that many call-stacks that use locks are actually identical, therefore it is only necessary to maintain a hash set of known call-stacks.

The BCC `offwaketime` tool performs a similar task to [[14](#_bookmark24)], except that it uses eBPF’s OS level tracing of kernel events associated with thread scheduling to determine: (1) the call-stack of a blocked thread, (2) its blocked time duration, and (3) the call-stack of the waking thread, which causes the scheduling state of the blocked thread to change to runnable. The call-stack of the blocking thread does not change whilst it is *off-core* and blocked. Hence, its callstack need only be recorded when it meets some selection criteria, such as belonging to a process that we are interested in, and if its blocking duration is within a specified range. This enables efficient and selective tracing of call-stack blocking and wakeup behavior due to thread interactions.

## 3   FLAMEGRAPH VISUALIZATIONS

Brendan Gregg [[13\] ](#_bookmark22)has shown that *scalable vector graphic* (SVG) visualizations of flamegraphs, see Figure [1, ](#_bookmark2)can aid identification of performance critical code from sampled stack traces. Stack traces can be related to processing core time, or to the change in a quantity, such as last level cache misses, from a hardware counter. In this way it is possible to produce flamegraphs that characterize the microarchitectural behavior of an application’s execution. SVGs enables flamegraphs to be viewed, zoomed in/out, and searched for text inside web browsers. The percentage contribution of a method is easily determined by searching for its name, whereupon each instance of the method in the graph is highlighted and its overall contribution to the total number of samples is displayed at the bottom right hand corner. This can be especially important for determining the relative contribution of methods having many different call-sites in an application.

In a flamegraph, any stack traces having identical callers are merged, then any non-identical child callee nodes in the collected traces appear as a new control flow path. Control flow paths are visualized by presenting the unique names of methods inside rectangular blocks that are typically organized lexicographically in order from left to right. Divergence in a control flow path is indicated by more than one rectangular block being stacked on top of another, such as for the blocks stacked on top of GangWorker::loop in our Figure [1. ](#_bookmark2)The topmost frame in a flamegraph is the method that

was executing when a call-stack was sampled. The topmost methods will be identified correctly as long as any sampling skid1 [[7\]](#_bookmark16) does not cause an incorrect method to be attributed. Note how the use of different colours can be used to distinguish between inlined Java, kernel, JIT compiled Java, C++, and native/library code. Interpreted Java methods are only labelled as Interpreter, and cannot be identified with perf/perf-map-agent. However, call-stacks and flamegraphs produced with async-profiler can identify methods that undergo interpreted execution. It is a fairly trivial matter, using options for async-profiler and perf to generate flamegraphs where thread PIDs are also captured with callstacks, this can sometimes be beneficial, but it can quickly become confusing if an application contains many threads.

*Identifying Inlined Methods.* In Figure [1, ](#_bookmark2)an inlined method appears as a teal/blue frame above a green Java JIT compiled method, further inlined methods appear as stacks of teal/blue frames. Inlining information accuracy is improved through the use of -XX:+DebugNonSafePoints. Note that flamegraph columns where a teal/blue rectangle/method is directly below green, indicate a place where the JIT compiled and inlined code has called a method that was chosen not to be inlined. Note that *on-core* flamegraphs, only demonstrate stacks for threads that were executing when sampling of call stacks occurred. They neglect the importance of *off-core* time when threads are blocked.

*Heap/Allocation Flamegraphs.* Figure [2](#_bookmark6) is an heap allocation flamegraph created using async-profiler, here the width of a call stack is proportional to the amount of heap memory allocation. The topmost call-stack element represents the allocated data type,

i.e. an array, such as char [], or an object such as StandardFilter. The profiler features TLAB-driven sampling that relies on callbacks (see AllocTracer in the OpenJDK/HotSpot sources) to receive notifications; i), when an object is allocated inside a newly created TLAB (annotated as INSIDE or aqua in Figure [2), ](#_bookmark6)and ii), when an object is allocated on a slow path outside a TLAB (annotated as OUTSIDE or in orange in Figure [2), ](#_bookmark6)for example when its size exceeds that of the TLAB. This means not every allocation is counted, but only allocations every N kB, where N is the average size of TLAB. This makes heap sampling very cheap and suitable for production, as in practice it will often reflect the top allocation sources, but the collected data may be incomplete.

*Offwaketime Flamegraphs.* The blocking latency associated with *off-cpu* time can be analysed with offwaketime flamegraphs. Figure [3 ](#_bookmark8)presents cropped illustrative output of the BCC/eBPF tool offwaketime for the avrora benchmark for blocking of thread node-0. The bottom stacks, colored blue, are off-core stacks that indicate the sequence of method calls leading to a thread blocking, and these are read from the bottom up leading towards the point where they blocked, that is separated from the waking thread stack by a grey block that is labelled --. The waking thread stacks, colored aqua, have their call-stack frames listed in reverse order, and are read from the top down, from application code, down to the method that caused the blocked thread’s scheduling state to change. The tool offwaketime achieves similar information to [[14\] ](#_bookmark24)for determining the blocking and wakeup behavior without requiring a modified JVM. A current limitation is that one wakeup stack may not be sufficient to explain all the sources of blocking latency. For example, when the "waker-thread" was itself blocked on another thread, potentially leading to a chain of blocking and wakeup stacks.