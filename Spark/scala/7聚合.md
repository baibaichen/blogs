# 第 7 章 Spark SQL 之 Aggregation 实现

聚合操作（ Aggregation ）指的是在原始数据的基础上按照一定的逻辑进行整合，从而得到新的数据，一般通过聚合函数（如 count、max 和 sum 等）汇总多行的信息。聚合查询一直以来都是数据分析应用中必不可少的部分，在各种 SQL 算子中占据着重要地位，本章对 Spark SQL 实现聚合查询的内部机制进行详细分析。

## 7.2　聚合函数（ AggregateFunction ）

聚合函数（ `AggregateFunction` ）是聚合查询中非常重要的元素。在实现上，聚合函数是表达式中的一种，和 **Catalyst** 中定义的聚合表达式（ `AggregateExpression` ）紧密关联。无论是在逻辑算子树还是物理算子树中，聚合函数都是以聚合表达式的形式进行封装的，同时聚合函数表达式中也定义了直接生成聚合表达式的方法。

聚合表达式（ `AggregateExpression` ）的成员变量和函数如图 7.7 所示，根据命名，这些变量和函数的含义很好理解。例如， resultAttribute 表示聚合结果，获取子节点的 children 方法并返回聚合函数表达式；dataType 函数直接调用聚合函数中的 dataType 函数获取数据类型。在默认情况下，聚合表达式的 foldable 函数返回的是 false，因为聚合表达式一般无法静态得到最终的结果，需要经过进一步的计算。

![img](https://pic4.zhimg.com/v2-28f6573ee001e02e3f8c10d563278706_r.jpg)

图 7.7 Aggregation 表达式

### 7.2.1　聚合缓冲区与聚合模式（ AggregateMode ）

聚合查询在计算聚合值的过程中，通常都需要保存相关的中间计算结果，例如 `max` 函数需要保存当前最大值，`count` 函数需要保存当前的数据总数，求平均值的 `avg` 函数需要同时保存 `count` 和 `sum` 的值，更复杂的函数（如 `pencentil` 等）甚至需要临时存储全部的数据。聚合查询计算过程中产生的这些中间结果会临时保存在聚合函数缓冲区。

#### 1.聚合函数缓冲区

聚合函数缓冲区是指在同一个分组的数据聚合的过程中，用来保存聚合函数计算中间结果的内存空间。

聚合函数缓冲区的定义有一个前提条件，即聚合函数缓冲区针对的是处于同一个分组内（实例中属于同一个 id）的数据。需要注意的是，查询中可能包含多个聚合函数，因此聚合函数缓冲区是多个聚合函数所共享的。

在聚合函数的定义中，与聚合缓冲区相关的基本信息包括：聚合缓冲区的 Schema 信息（ `aggBufferSchema` ），返回为 `StructType` 类型；聚合缓冲区的数据列信息（ `aggBufferAttributes` ），返回的是 `AttributeReference` 列表（`Seq[ AttributeReference ]`），对应缓冲区数据列名。显然，聚合函数缓冲区中的值会随着数据处理而不断进行更新，因此该缓冲区是可变的（**Mutable**）。此外，当聚合函数处理新的数据行时，需要知道该数据行的列构成信息，在 `AggregateFunction` 中也定义了 `inputAggBufferAttributes` 函数来获得输入数据的组成情况。通常情况下， `inputAggBuffereAttributes` 返回的都是自动从 `aggBufferAttributes` 获得的结果。

#### 2.聚合模式

在 Spark SQL 中，聚合过程有 4 种模式，分别是 Partial 模式、 ParitialMerge 模式、Final 模式和 Complete 模式。

**Final 模式一般和 Partial 模式组合在一起使用**。Partial 模式可以看作是局部数据的聚合，在具体实现中，Partial 模式的聚合函数在执行时会根据读入的原始数据更新对应的聚合缓冲区，当处理完所有的输入数据后，返回的是聚合缓冲区中的中间数据。而 Final 模式所起到的作用是将聚合缓冲区的数据进行合并，然后返回最终的结果。如图 7.8 所示，在最终分组计算总和之前，可以先进行局部聚合处理，这样能够避免数据传输并减少计算量。因此，上述聚合过程中在 map 阶段的 sum 函数处于 Partial 模式，在 reduce 阶段的 sum 函数处于 Final 模式。

![img](https://pic2.zhimg.com/v2-958e4a278451260870ca6b2917c088de_r.jpg)

图 7.8　Partial 与 Final 聚合模式

**Complete 模式**和上述的 Partial/Final 组合方式不一样，不进行局部聚合计算。图 7.9 展示了同样的聚合函数采用 Complete 模式的情形。可以看到，最终阶段直接针对原始输入，中间没有局部聚合过程。一般来讲，在不支持 Partial 模式的聚合函数中应用 Complete 模式。

![img](https://pic2.zhimg.com/v2-6bafc0018e5c5c8b392908230ca53d6c_r.jpg)

图 7.9　Complete 聚合模式

相比 Partial、Final 和 Complete 模式， **PartialMerge 模式的聚合函数**主要是对聚合缓冲区进行合并，但此时仍然不是最终的结果。 ParitialMerge 主要应用在 distinct 语句中，如图 7.10 所示。聚合语句针对同一张表进行 sum 和 count（distinct）查询，最终的执行过程包含了 4 步聚合操作。第 1 步按照（A，C）分组，对 sum 函数进行 Partial 模式聚合计算；第 2 步是 PartialMerge 模式，对上一步计算之后的聚合缓冲区进行合并，但此时仍然不是最终的结果；第 3 步分组的列发生变化，再一次进行 Partial 模式的 count 计算；第 4 步完成 Final 模式的最终计算。

![img](https://pic2.zhimg.com/v2-9f0e38ee9c56f6c5c4dc2fccf4ca4930_r.jpg)

图 7.10 PartialMerge 聚合模式

------

### 7.2.2 DeclarativeAggregate 聚合函数

`DeclarativeAggregate` 聚合函数是一类直接由 Catalyst 中的表达式（ Expressions ）构建的聚合函数，主要逻辑通过调用 4 个表达式完成，分别是 initialValues （聚合缓冲区初始化表达式）、 updateExpressions （聚合缓冲区更新表达式）、 mergeExpressions （聚合缓冲区合并表达式）和 evaluateExpression （最终结果生成表达式）。下面以 Count 函数为例对这种类型的聚合函数的实现进行说明。

![img](https://pic3.zhimg.com/v2-ca01f31bbc990af85703b29729c357eb_r.jpg)

通常来讲，实现一个基于表达式的 DeclarativeAggregate 函数包含以下几个重要的组成部分。

- 定义一个或多个聚合缓冲区的聚合属性（ bufferAttribute ），例如 count 函数中只需要 count，这些属性会在 updateExpressions 等各种表达式中用到。
- 设定 DeclarativeAggregate 函数的初始值，count 函数的初始值为 0。
- 实现数据处理逻辑表达式 updateExpressions ，在 count 函数中，当处理新的数据时，上述定义的 count 属性转换为 Add 表达式，即 count+1L，注意其中对 Null 的处理逻辑。
- 实现 merge 处理逻辑的表达式，函数中直接把 count 相加，对应上述代码中的「 count.left + count.right 」，由 DeclarativeAggregate 中定义的 RichAttribute 隐式类完成。
- 实现结果输出的表达式 evaluateExpression ，返回 count 值。

### 7.2.3 ImperativeAggregate 聚合函数

不同于基于 Catalyst 表达式实现 `DeclarativeAggregate` 聚合函数方式， `ImperativeAggregate` 聚合函数需要显式地实现 `initialize` 、`update` 和 `merge` 方法来操作聚合缓冲区中的数据。一个比较显著的不同是， `ImperativeAggregate` 聚合函数所处理的聚合缓冲区本质上是基于行（ `InternalRow` 类型）。

聚合缓冲区是共享的，可能对应多个聚合函数，因此特定的 `ImperativeAggregate` 聚合函数会通过偏移量进行定位。例如，数据表有 3 列，分别是 key、x、y，查询语句中有两个求平均值的函数 avg（x）和 avg（y）（注：假设这里用 `ImperativeAggregate` 的方式来实现平均值函数）。这两个函数共享聚合缓冲区`[sum1，count1，sum2，count2]`，如图 7.11 所示，那么第一个 avg 函数的缓冲区偏移量为 0，第二个 avg 函数的缓冲区偏移量为 2，可以通过 `mutableAggBufferOffset + fieldNumber` 方式来访问具体的中间变量。

![img](https://pic2.zhimg.com/v2-a092fe1d1181c743956b57bb5ca7959e_r.jpg)

图 7.11 ImperativeAggregate 聚合函数

在 ImperativeAggregate 聚合函数中，还有输入聚合缓冲区（ InputAggBuffer ）的概念。 Input-AggBuffer 是不可变的，在聚合处理过程中将两个聚合缓冲区进行合并的时候，实现方式就是将该缓冲区的值更新到可变的聚合缓冲区中。除不可变外， InputAggBuffer 中相对聚合缓冲区还可能包含额外的属性，例如 group by 语句中的列，对应的缓冲区即[key，sum1，count1，sum2，count2]。因此，在 ImperativeAggregate 聚合函数中还有 inputAggBuferOff set 的概念，用来访问 InputAggBuffer 中对应的中间值。

------

### 7.2.4 TypedImperativeAggregate 聚合函数

`TypedImperativeAggregate[T]`聚合函数允许使用用户自定义的 Java 对象 T 作为内部的聚合缓冲区，因此这种类型的聚合函数是最灵活的。不过需要注意的是， Typed ImperativeAggregate 聚合缓冲区容易带来与内存相关的问题。通常来讲， Typed ImperativeAggregate 聚合函数的执行逻辑分为以下几步。

1. **初始化聚合缓冲区对象**。聚合算子执行框架会调用 `initialize` 函数创建一个空的聚合缓冲区。 `initialize` 函数会执行 `createAggregationBuffer` 函数来获得初始化的缓冲区对象，并将其设置**在全局的缓冲区中**。
2. **处理输入数据**
   1. 如果当前聚合函数的聚合模式是 **Partial 或 Complete** ，则执行框架会调用 `update` 函数来处理输入的数据行。在 update 函数的实现逻辑中，会从**全局缓冲区**获得缓冲对象，然后对其数据进行更新。
   2. 如果当前聚合函数的聚合模式是 **PartialMerge 或 Final**，则执行框架会调用 merge 函数来处理数据，所处理的数据来自于其他节点序列化后的缓冲区对象。在 merge 函数的实现逻辑中，会将二进制数据反序列化成对应的 Java 对象，然后进行合并操作
3. **输出结果**
   1. 如果当前聚合函数的聚合模式是 **Partial 或 PartialMerge** ，则执行框架会调用 `serializeAggregateBufferInPlace` 函数将全局聚合缓冲区中的 Java 对象替换为序列化后的二进制数据，并将它们 Shuffle 到其他的节点。
   2. 如果当前聚合函数的聚合模式是 **Final 或 Complete**，则执行框架会调用 eval 函数来计算最终的结果并将结果返回。

*Note* ： Typed ImperativeAggregate 聚合函数采用二进制数据类型 BinaryType 作为聚合缓冲区的存储方式，而 BinaryType 不支持基于 hash 的聚合方式，因此当聚合算子中包含 Typed Imperative-Aggregate 聚合函数时，一般实现为 **sortaggregation** 方式。

## 7.3　聚合执行

聚合执行本质上是将 RDD 的每个 Partition 中的数据进行处理。如图 7.12 所示，对于每个 Partition 中的输入数据即 Input（通过 `InputIterator` 进行读取），经过聚合执行计算之后，得到相应的结果数据即 Result（通过 Aggregation Iterator 来访问）。

![img](https://pic1.zhimg.com/v2-c683a410549736693bcdcce57059ce62_r.jpg)

图 7.12　聚合执行

在 Spark 2.1 版本中，聚合查询的最终执行有两种方式：基于排序的聚合执行方式（ `SortAggregateExec` ）与基于 Hash 的聚合执行方式（ `HashAggregateExec` ）。在后续版本中，又加入了 `ObjectHashAggregateExec` 的执行方式（SPARK-17949），读者可自行研究其实现方式。常见的聚合查询语句通常采用 HashAggregate 方式，当存在以下几种情况时，会用 SortAggregate 方式来执行。

- 查询中存在**不支持 Partial 方式的聚合函数**：此时会调用 AggUtils 中的 `planAggregateWithoutPartial` 方法，直接生成 SortAggregateExec 聚合算子节点。
- 聚合函数结果不支持 Buffer 方式：如果结果类型不属于[NullType， BooleanType ，Byte-Type，ShortType， IntegerType ，LongType，FloatType， DoubleType ，DateType， TimestampType ， DecimalType ]集合中的任意一种，则需要执行 SortAggregateExec 方式，例如 collect_set 和 collect_list 函数。
- 内存不足：如果在 HashAggregate 执行过程中，内存空间已满，那么聚合执行会切换到 SortAggregateExec 方式，这种情况将在 7.3.3 小节进行分析。

聚合查询的执行过程有一个通用的框架，主要接口定义在图 7.12 中的 Aggregation Iterator 中。本节后续内容首先介绍 Aggregation Iterator 的实现，然后分别分析 SortAggregate 与 HashAggregate 的技术实现原理。

### 7.3.1　执行框架 Aggregation Iterator

聚合执行框架指的是聚合过程中抽象出来的通用功能，包括聚合函数的初始化、聚合缓冲区更新合并函数和聚合结果生成函数等。这些功能都在聚合迭代器（ Aggregation Iterator ）中得到了实现。

如图 7.13 所示，聚合迭代器定义了 3 个重要的功能，分别是

1. **聚合函数初始化**： `initializeAggregateFunctions`
2. **生成数据处理函数**：`generateProcessRow`
3. **生成聚合结果输出函数**：`generateResultProjection`

 `SortBasedAggregationIterator` 和 `TungstenAggregationIterator` 继承自 `AggregationIterator` ，实现具体的操作，分别对应 `SortAggregateExec` 和 `HashAggregateExec` 两种执行方式。在 `SortBasedAggregationIterator` 和 `TungstenAggregationIterator` 中分别通过 processCurrentSortedGroup 与 processInputs 方法得到最终的聚合结果，而这两个方法均依赖上述 Aggregation Iterator 功能。

**<u>第一个功能聚合函数初始化可以细分为两个阶段</u>**，分别得到 `funcWithBoundReference` 和 `funcWithUpdatedAggBufferOffset` 表达式。**第一阶段**， `funcWithBoundReference` 执行 `bindReference` **或**设置聚合缓冲区偏移量。针对 **Partial 和 Complete** 模式的 `ImperativeAggregate` 聚合函数， `AttributeReference` 表达式会转换为 `BoundReference` 表达式。例如，假设 `Count(A)` 处理的输入数据行为整型的（A，B，C），经过转换后，得到的是 `Count(BoundReference [0，Int，false])`，提取出的是属性下标等信息；而对于 **PartialMerge 和 Final** 模式的 `ImperativeAggregate` 聚合函数，会设置输入缓冲区的偏移量 `withNewInputAggBufferOffset` 。**第二阶段**， `funcWithUpdatedAggBufferOffset` 设置 `ImperativeAggregate` 函数聚合缓冲区的偏移量 `withNewMutableAggBufferOffset` 。

![img](https://pic4.zhimg.com/v2-341ccbb46c62fb36399bfc2152893916_r.jpg)

图 7.13　执行框架 Aggregation Iterator

**第二个功能生成数据处理函数，得到数据处理函数** `processRow` ，其参数类型是（ InternalRow ， InternalRow ），分别代表当前的聚合缓冲区 **currentBufferRow** 和**输入数据行 row**，输出是 Unit 类型。数据处理函数 processRow 的核心操作是获取各 Aggregation 中的 update 函数或 merge 函数。

1. 对于 **Partial** 和 **Complete** 模式，处理的是原始输入数据，因此采用的是 update 函数
2. 对于 **Final** 和 **PartialMerge** 模式，处理的是聚合缓冲区，因此采用的是 merge 函数。

```scala
val updateFunctions = functions.zipWithIndex.collect {
  case (ae: ImperativeAggregate, i) =>
  expressions(i).mode match {
    case Partial | Complete =>
    (buffer: InternalRow, row: InternalRow) => ae.update(buffer, row)
    case PartialMerge | Final =>
    (buffer: InternalRow, row: InternalRow) => ae.merge(buffer, row)
  }
}.toArray
```

**第三个功能生成聚合结果输出函数，计算最终的聚合结果**，输入类型是（UnsafeRow， InternalRow ），输出的是 `UnsafeRow` 最终的数据类型。

1. 对于 **Partial** 或 **PartialMerge** 模式的聚合函数，因为只是中间结果，所以需要保存 grouping 语句与 buffer 中所有的属性
2. 对于 **Final** 和 **Complete** 聚合模式，直接对应 `resultExpressions` 表达式。特别注意，如果不包含任何聚合函数且只有分组操作，则直接创建 projection 。

------

### 7.3.2　基于排序的聚合算子 SortAggregateExec

基于排序的聚合算子 SortAggregateExec 的实现比较简单。顾名思义，这是一种基于排序的聚合实现，在进行聚合之前，会根据 grouping key 进行分区并在分区内排序，将具有相同 groupingkey 的记录分布在同一个 partition 内且前后相邻。如图 7.14 所示，聚合时只需要顺序遍历整个分区内的数据，即可得到聚合结果。

通过查看 SortAggregateExec 实现可知， requiredChildOrdering 中对输入数据的有序性做了约束，分组表达式列表（ groupingExpressions ）中的每个表达式 e 都必须满足升序排列，即 SortOrder （e，Ascending），因此在 SortAggregateExec 节点之前通常都会添加一个 SortExec 节点。 SortBasedAggregation Iterator 是 SortAggregateExec 实现的关键，由于数据已经预先排好序，因此实现相对简单，按照分组进行聚合即可。在其具体实现中， currentGroupingKey 和 nextGroupingKey 分别表示当前的分组表达式和下一个分组表达式， sortBasedAggregationBuffer 为其聚合缓冲区。比较重要的方法是 initialize 和 processCurrentSortedGroup ，用来初始化基本信息和当前分组数据的处理。

![img](https://pic1.zhimg.com/v2-bcfce22fc2eb18aca81600da79445f71_r.jpg)

图 7.14　基于排序的聚合算子 SortAggregateExec 的执行过程

分组数据处理算法逻辑如 Algorithm 1 所示，由算法可知，在 while 循环过程中，不断获取输入数据并将其赋值给 currentRow ，执行 groupingProjection 得到 groupingKey 分组表达式。如果当前的分组表达式 currentGroupingKey 和 groupingKey 相同，那么意味着当前输入数据仍然属于同一个分组内部，因此调用 Aggregation Iterator 中得到的 processRow 函数来处理当前数据。注意，数据处理之前首先通过 safeProj 将 currentRow 从 Unsafe 类型转换为 Safe 类型。

------

### 7.3.3　基于 Hash 的聚合算子 HashAggregateExec

HashAggregateExec 从逻辑上很好实现，只要构建一个 Map 类型的数据结构，以分组的属性作为 key，将数据保存到该 Map 中并进行聚合计算即可。然而，在实际系统中，无法确定性地申请到足够的空间来容纳所有数据，底层还涉及复杂的内存管理，因此相对 SortAggregateExec 的实现方式反而更加复杂。

![img](https://pic1.zhimg.com/v2-4b793dd46ddc3c414a519bcd568f5239_r.jpg)

观察 HashAggregateExec 的实现， requiredChildDistribution 对输入数据的分布做了约束，如果存在分区表达式，那么数据分布必须是 ClusteredDistribution 类型。类似 SortAggregateExec 中的情形， HashAggregateExec 的实现关键在于 TungstenAggregation Iterator 类，如图 7.15 所示。整体实现机制很容易理解，核心之处在于 UnsafeFixedW idthAggregationMap 这种特殊的 Map 数据结构。

![img](https://pic4.zhimg.com/v2-472e5c6e499d0b9e7fcba8acc256fcfe_r.jpg)

图 7.15　基于 Hash 的聚合执行过程 HashAggregateExec

实际上， HashAggregateExec 可能因为内存不足的原因退化为 SortAggregateExec 执行方式，因此 TungstenAggregation Iterator 需要处理各种场景，相比 SortBasedAggregation Iterator 的实现要复杂得多。从整体上来看， TungstenAggregation Iterator 代码包含 8 部分内容。

- 聚合函数初始化相关的操作。
- 设置聚合缓冲区、数据处理和聚合结果生成的各种方法。
- 执行基于 Hash 聚合方式的各种方法。
- 切换到基于排序聚合的各种方法。
- 执行基于排序聚合方式的各种方法。
- 加载输入数据并处理输入数据的各种方法。
- 提供给外部调用的 Iterator 公共方法。
- 在不包含分组表达式或没有输入的情况下生成结果的辅助方法。

TungstenAggregationIterator 通过执行 processInputs 方法触发聚合操作，其主要逻辑如 Algorithm 2 所示。当分组表达式 groupingExpressions 为空时，过程比较简单，只要在获取输入数据的迭代过程中不断调用 processRow 函数来处理数据即可，因此算法省略了此部分内容。

这里以 processInputs 方法中的逻辑为主线梳理一下聚合操作的过程：在 while 循环中不断获取输入数据 new Input ，然后得到分组表达式 groupingKey ，并以此为 key 到 hashMap（注： UnsafeFixedW idthAggregationMap 类型，内部存储 groupingKey 与 UnsafeRow 的映射关系）中获取对应的聚合操作缓冲区（buffer），如果 buffer 不为空，则直接调用 processRow 处理。如果获取不到对应的 buffer，则意味着 hashMap 内存空间已满，这种情况下调用 destructAndCreate-ExternalSorter 方法将内存数据 spill 到磁盘以释放内存空间。注意，spill 到磁盘的数据会通过 UnsafeKVExternalSorter 数据结构访问，多次 spill 的外部数据还会进行合并操作。然后，再次从 hashMap 获取聚合缓冲区，此时如果无法获取，则会抛出 OOM 错误。

最后，检查全局 externalSorter 对象，如果不为空，则意味着聚合操作过程因为内存不足没能执行成功，部分数据存储在磁盘上。此时，将 hashMap 中最后的数据 spill 到磁盘并与 externalSorter 中的数据合并，然后调用 free 方法释放 hashMap，切换到基于排序的聚合执行方式。具体实现参考 sw itchToSortBasedAggregation 方法，其逻辑与 SortAggregateExec 方式的逻辑类似，这里不再展开讲解。

总体来看， HashAggregateExec 的执行过程还是比较清晰的，内存不足时借助磁盘空间实现聚合。中间涉及的一些特殊的数据结构（包括 UnsafeKVExternalSorter 和 UnsafeFixedW idthAggregationMap 等），其内部实现细节读者可以先暂时跳过，待熟悉了 Tungsten 相关的内容之后再自行研究。

![img](https://pic3.zhimg.com/v2-816a73f5923a3e0b9f4527427cda181c_r.jpg)