## 4-事务技术

上节是关于如何优化B-tree数据结构及其算法的综述，本节关注B-tree的『并发控制和恢复相关』的技术。现实系统中，磁盘数据结构（主要是B-tree）的『绝大部分开发和测试工作』主要是并发控制和恢复。本节和随后几节描述的几个技术，使得『传统的数据库管理系统』与『现今各种Web服务使用的Key-Value存储系统』显著不同[Chang et al. 2008, DeCandia et al. 2007]。

本节描述的B-tree不仅支持只读搜索，同时也支持并发修改：即插入、删除、以及修改已存在的记录（包括键值和普通字段）。我们关注的是即时修改，而非是**差分文件**这类使用延迟更改的技术。下一节描述更新计划（update plans），用于在『成熟的数据库管理系统』中维护相关的多个索引、物化视图、完整性约束等。

由于在众多用户和应用程序之间共享数据，就能说明建立数据库的复杂性和高代价，因此从一开始，在并发事务和执行线程之间访问共享数据库，就和高可用性以及『快速可靠地从故障软硬件中恢复』一样，处在数据库研发的最前沿。最近，多核处理器使得高度并发的内存数据结构获得更多的关注，事务内存可能是一种解决方案，但这要求正确地理解事务的边界，因此需要选择一致的中间状态。

除了并发用户之外，还存在一种使用异步工具的趋势，它们在持久性存储上执行可选或是强制性任务。一个常见的例子是：从数据库删除表或是索引后，并不是马上将它们的页面加到空闲空间中去，而只是简单地把它们标记为过期，这就要有强制性异步任务来合并空闲空间。『可选异步任务』的常见例子是碎片整理，即为了高效的『区间查询和索引序扫描』，而在B-tree叶子之间平衡负载和优化磁盘布局。还有其它许多异步任务，并不特定属于B-tree，比如收集和更新『用于编译时优化查询』的统计信息。

> ==TODO：==Fig.4.1

图4.1列出了事务的“ACID”四个属性及其简要的解释，这些属性的细节在数据库教科书中有更加深入地论述。这里值得通过一个具体的例子，进一步澄清原子性中“逻辑”一词的含义：假设用户事务尝试在数据库的表中插入一条新记录，为了获得足够的空间，不得不分裂B-tree的节点，但是节点分裂后事务就失败了；事务回滚时，必须撤销插入操作，不过为了确保数据库的内容正确，并不需要严格地要求合并分裂的节点。如果分裂节点的效果仍然保留在数据库中，即使事务回滚后存在“物理变化”，但逻辑上数据库并没有改变。这里“逻辑”是根据“查询结果”来定义；“物理”是根据『磁盘中的位』这样的物理表示来定义。

逻辑数据库和物理数据库之间的不同，或是数据库内容和数据库表示之间的不同，渗透到下面的讨论。一个特别有用的概念是“系统事务”，即对数据库内容没有影响，但在数据表示层面有变化的事务（这类事务仍会在数据表示层面修改，生成日志和提交改变）。对于B-tree的节点分裂、空间分配和回收等，系统事务特别有用。在上面的例子中，当用户事务回滚时，分裂后的节点（由系统事务提交）仍然原地保留。系统事务一般都很简单，并运行在单个线程中，通常是在执行用户事务的线程中，这样用户事务将会等待系统事务完成。如果用户事务运行在多个线程中，那么每个线程可以调用自己的系统事务。

如果将大表或索引分区，并将分区指派到分布式系统中多个节点中，那么通常都是在节点内执行各自的并发控制，在需要的时候，通过两阶段提交来协调恢复。如果在单个站点内使用多个恢复日志，那么要用到同样的技术。本文是关于B-tree索引的综述，分布式事务、两阶段提交等超出了本书的范围。

> ==TODO：==Fig.4.2

并发控制的常用机制就是锁。基本的锁模式，即——共享锁（S）、独占锁（X）和更新锁（U）——之间的兼容性矩阵，如图4.2所示。左列表示当前持有的锁，顶行表示当前请求的锁，矩阵中的空格表示不能授予请求的锁。两个共享锁是兼容的，显然这就是共享的要点；反之独占锁和其它类型的锁都不兼容。共享锁也被称之为读锁，独占锁则被被称之为写锁。

对于允许的锁请求，这个兼容矩阵显示了（锁请求成功后）的聚合模式，目的是为了加速处理新的锁请求，即使有许多事务持有某个特定资源的锁，新的锁请求也只需检查是否与聚合后的锁模式兼容，而不必检查是否与『该资源上所有的』锁模式兼容。换言之，图4.2中左列表示（资源）当前的锁模式，就是当前的聚合模式。大多数情况下，图4.2中锁的聚合模式都不重要。后续有一个例子，包含了更多锁模式，新的聚合模式即不等于老的聚合模式，也不等于请求的锁模式。图4.2没有反应的一个特殊情况是将锁从更新模式降级为共享模式，由于只有一个事务能持有更新锁，从更新模式降级为共享模式后，锁的聚合模式是共享锁。

应用程序有时需要先测试一个条件，再决定是否更新数据记录，这就需要用到更新锁。如果一开始就采用独占锁，这阻止了处理同样逻辑的其它事务；如果采用共享锁，倒是允许两个事务同时锁定共享的数据，但是当它们都试图升级成独占锁时，将会导致死锁！更新锁一次只允许一个事务处于此种状态：即不清楚自己未来将执行何种操作。完成条件测试后，更新锁要么确实升级成独占锁，要么降级成共享锁。注意，更新锁并不比共享锁有更多的权利，它们之间的不同主要是在调度和死锁预防，而不是在并发控制和访问数据的权利。这样，降级到共享锁是允许的。

更新锁也被称之为升级锁。考虑到更新锁并不是授予锁更新数据的权利，而是锁升级的优先级，因此“升级锁”是一个更加准确的名字，然而，更新锁似乎变得越来越常用。Korth在[Korth 1983]中深入考察了派生的锁模式（比如升级锁）和基本的锁模式（比如共享锁和独占锁）之间的关系。

注意图23中那个带问号的字段，当事务持有（某个资源的）更新锁时，有些系统允许新的事务请求（该资源的）共享锁，有些则不允许。前面的处理方式，仅当事务请求互斥锁时，才不再允许额外的共享锁请求；最可能的是（但并不是百分之百）『持有更新锁的事务』请求互斥锁。因此，即使后面的方案在锁矩阵中引入了不对称性，但它能更有效地预防死锁[Gray and Reuter1993]。后面锁矩阵的例子都假设这种不对称的设计。

出故障时『保证原子性和持久性』的主要手段是先写日志，这就要求在『就地修改数据库』之前，先在恢复日志中记录『数据库的变化』。因此，每种类型的“修改”操作需要：一个“do”方法，在初始处理时调用；一个“redo”方法，在出现故障，或是数据库崩溃时，确保数据库处于“修改”后的状态；一个“undo”方法，将数据库恢复至“修改”之前的状态。由“do”方法创建『包含足够信息的日志记录』，以便调用“redo”和“undo”；并指示缓冲池保留这些脏页，直到对应的日志安全地到达“稳定的存储”。因为稳定的存储是可靠的，所以恢复也是可靠的。镜像日志设备是一个通用的技术。日志页一旦生成，就决不能被修改或是覆盖[1]。

早期的恢复技术要求“redo”和“undo”是幂等的[56]，即不管『应用同样的操作多少次』，结果都一样。一个潜在的假设就是，恢复日志在恢复时是只读的，也就是从故障中恢复时，不生成日志。后来的技术，尤其是ARIES[95]，通过为“undo”操作生成恢复日志，并在数据页上保存“Page LSN”（日志序列号）以指明『该页所包含的最近的更新』，来确保只会应用“redo”和“undo”操作一次。此外，逻辑“补偿”，而非物理“补偿”更新操作，比如，删除补偿插入，然而，如果在『B-tree索引的叶节点分裂』之后再删除，那么删除的叶节点和插入的叶节点可能并不相同。中止事务只需生成更新的“补偿记录”，然后正常提交即可，唯一不同的是，此时无需强迫刷新提交记录到稳定存储。

- ACID四个属性（原子性、一致性、隔离性和持久性）定义了事务。先写日志和“do-redo-undo”三人组是恢复和可靠性的基础。Latching和Locking是并发控制的基础
- 在B-tree中，记录级的锁定是指『key-value locking』和『key-range locking』。锁的粒度（即，记录级或是Key级）小于恢复的粒度（即，页级）需要在日志中记录“undo”操作，在恢复时实施逻辑补偿，而不是通过调用『无需在日志中记录的』幂等操作，来实施严格的物理恢复
- 独立物理数据，区分数据库的**逻辑内容**和**物理表示**。这样，在数据库系统的关系层，数据库的物理设计是独立的，且必须自动优化查询；在数据库的存储层，使得『并发控制和恢复的实现』可以有很多优化。
- 一个重要的优化是区分用户事务和系统事务：用户事务『查询或者修改数据库的逻辑内容』；系统事务『则只影响逻辑内容的物理表示』。在系统事务中分裂B-tree的节点，是其优点的一个经典例子。

### 4.1线程锁（Latching） and 事务锁（Locking）

B-tree或是B-tree索引中的加锁有两层含义。一是在**并发的数据库事务**之间实施并发控制，并发事务查询或修改数据库，在该上下文中，主要考虑的是数据库的逻辑内容，而不是其物理表示（比如像B-tree索引这样的数据结构）。二是在**并发的线程**之间实施并发控制，并发线程修改的是内存中的数据结构，这里内存中的数据结构尤其是指『基于磁盘的B-tree节点』在缓存池中的内存映像。

这两方面并不总是区分的很清晰。**但当多个并行线程处理某个数据库请求时，它们之间的区别就变得非常明显了**。具体地说，同一个事务里的两个线程必须“看到”同样的数据库内容，数据库表里有相同的记录数；这还包括事务的某个线程必须要能“看到”代表该事务的另一个线程所实施的修改。然而，当一个线程正在分裂B-tree的节点时，也就是『在特定的数据结构中』修改数据库的物理表示时，其它的线程不能观察到不完整的中间结果。**另一方面，当单个线程为多个事务服务时，它们之间的区别也非常明显**。

|            | 事务锁                   | 线程锁                    |
| ---------- | ------------------------ | ------------------------- |
| 隔离 …     | 用户事务                 | 线程                      |
| 保护 …     | 数据库内容               | 内存数据结构              |
| During …   | 整个事务^2^              | 临界区                    |
| Modes …    | 共享、互斥、更新、       | 读, 写,                   |
|            | 意图、escrow, schema,等. | (可能)更新                |
| Deadlock … | 检测 & 解决              | 避免                      |
| … by …     | 等待图的分析,            | 编码规则,                 |
|            | 超时, 事务中止,          | instant-timeout requests, |
|            | 部分回滚, 锁降级         | “锁分层”^3^               |
| Kept in …  | 锁管理器的哈希表中       | 被保护的数据结构中        |
图4.3 事务锁（Locks）和线程锁（latchs）

> 2. 事务必须保持锁定，直到事务提交，以便等价于串行执行，也称为事务隔离级别“可串行化”。较弱的事务隔离锁的持续时间较短。在许多数据库系统中，默认弱事务隔离，因此以正确和完全隔离并发事务为代价实现更高的并发性。
> 3. 在这种技术中，层次被分配给『线程锁』，线程只能请求高于已持有『线程锁』层次的『线程锁』。

图4.3总结了它们之间的不同。『事务锁』使用读写锁来隔离事务，可以锁定B-tree的页、B-tree的键值，还可以锁定两个键值之间的空隙（开区间）。后面两种锁定方式也被称之为『键值锁定』和『键区间锁定』。『键区间锁定』是谓词锁定的一种形式，这里的谓词是用『实际的B-tree键值』和『B-tree的排序顺序』来定义的。缺省情况下，『事务锁』支持死锁检测，并且在事务提交后才会被释放。『事务锁』亦支持复杂的调度，比如：使用队列缓存等待处理的锁请求；推迟新锁的获取以便完成锁转换（比如，将现有的共享锁转换成互斥锁）。这种级别的复杂性使得『事务锁』的获取和释放相当昂贵，通常需要执行数百个CPU指令，并耗时上千个CPU周期，这包括由『锁管理器中哈希表的缓存失效』而引入的CPU周期。图4.3总结了它们之间的不同。

『线程锁』隔离线程，所有由多个线程共享的内存数据结构，包括B-tree的页、缓冲池的管理表，都由『线程锁』来保护，由于多个线程会共享『锁管理器』的哈希表，因此，当检查或修改『数据库系统事务锁』的信息时，必须请求『线程锁』；对于共享的数据结构，如果事务的某个线程需要一个写锁，即使是同一个事务的其它线程也会与之冲突；只在重要的地方申请『线程锁』，即，读取或修改共享数据结构的代码里。通过恰当的编码规则，比如，小心设计多个『线程锁』的请求顺序，来避免『线程锁』之间的死锁。处理死锁需要有办法回滚到先前的状态，避免死锁则不需要，因此开销更小、性能和扩展性更好，这样，避免死锁对『线程锁』更合适。获取和释放『线程锁』可能只需要数十条指令；同时，有关『线程锁』的信息可以嵌入在其保护的数据结构中，这通常不会引入额外的缓存失效。对于缓冲池中磁盘页的映像，『线程锁』的信息可以嵌入在『包含页标识符的描述结构』中。

由于『事务锁』与数据库内容有关，而与它们的物理表示无关，因此，如果数据都存储在B-tree的叶节点中，那么『事务锁』就不必保护B-tree的非叶节点；相反，『线程锁』则要保护B-tree中的所有节点（无论这些节点在数据库的角色是什么）。『事务锁』和『线程锁』之间的不同，在对二级索引（指向唯一一份数据存储的冗余索引）实施并发控制时，也变得很明显。例如，ARIES/IM[97]的『data-only的锁定模式』，只需锁定（记录的标志符）一次，无需锁定二级索引上对应的键值，就可以保护从属于逻辑行的所有记录（包括B-tree中的记录），从而在更细的粒度上隔离事务，并获得更高的并发性。相反，『由多个线程并发访问』的内存数据结构都要用『线程锁』保护，这显然包括二级索引上的所有节点和页面。

- 『线程锁』协调线程，保护的是内存中的数据结构，包括缓冲池中磁盘页的映像；『事务锁』协调事务，保护数据库内容。
- 事务和『事务锁』需要检测和处理死锁；线程和『线程锁』则需要避免死锁，这需要制定编码规则，请求『线程锁』时，若遇冲突只能选择失败，而非等待。
- 『线程锁』和临界区密切相关，可以由硬件提供支持，例如『硬件事务内存』

### 4.2 幻影记录

如果在事务中删除B-tree记录，那么在提交事务提前，必须保留回滚事务的能力。因此，必须确保在回滚事务时，空间分配不会失败，并且另一个事务不能插入有相同唯一B-tree键的新记录。满足这些要求的一种简单技术是将记录及记录的键保留在B-tree中，仅将其标记为无效；在提交删除记录的事务之前，一直锁定它们（记录及记录的键）。另一个好处是，用户事务可以延迟处理甚至避免一些空间管理工作，例如，移动页面间接数组中的元素。此外，用户事务只需锁定被删除的记录，而不是记录两个相邻键之间的整个键区间。

结果记录称为伪删除记录或**幻影记录**。记录头中的一个位足以指示记录的幻影状态。因此，**<u>删除变成了对幻影位的修改</u>**。如果并发控制依赖于**键区间锁定**（下面讨论），则只需要锁定键本身，并且键之间的所有间隙可以保持未锁定状态。

> ==TODO：==Fig.4.4

图4.4显示了一个带有幻影记录的B-tree页面，即在删除键为27的记录后的中间状态。显然，这是在页面内的移除幻影和回收空间之前。有效记录包含一些与其键相关联的信息，用省略号表示，而幻影记录中的信息字段可能会保留，但没有意义。回收空间的第一步可以尽可能地缩短这些区域，尽管首选方法可能是完全删除幻影记录。

查询必须忽略（跳过）幻影记录；因此，扫描带幻影记录的系统始终含有隐藏的谓词，尽管该谓词的计算内置在B-tree代码中，而无需谓词解释器。回收空间留给后续事务，可能是一个插入（需要比页面中已有空闲空间更多的空闲空间）、显式调用页面压缩或B-tree碎片整理实用工具。

幻影记录被锁定时无法删除。换言之，幻影记录至少在原地被保留到（删除它的）事务提交，将有效记录变成幻影记录。随后，另一个事务可能会锁定一个幻影记录，例如，以确保继续缺少该键值。锁定不存在的键值对于可串行化至关重要；没有它，在同一事务中重复查询 `select count(*)` 可能会返回不同的结果。

同一页中可能同时存在多个幻影记录，一个系统事务就可以删除所有这些记录。将删除幻影的日志记录与提交事务的日志记录合并，则无需在日志中记录已删除记录的内容。==<u>合并这些日志记录使事务不可能在幻影删除和提交之间失败</u>==。因此，永远不需要回滚幻影删除，从而恢复日志中的记录内容。换句话说，幻影记录不仅可以确保在需要时成功地回滚事务，而且还经常减少与删除相关的日志总量。

> ==TODO：==Fig.4.5

图4.5说明了没有和使用幻影记录时，删除事务的日志。在左侧，用户事务删除记录并记录其全部内容。如果需要，可以使用恢复日志中的信息重新插入记录。在右侧，用户事务只修改幻影位。稍后，系统事务会创建一条日志记录，包含事务启动、幻影删除和事务提交。无法从恢复日志中重新插入已删除的幻影记录，但这没有必要，因为此时删除操作已经提交了。

如果使用与B-tree中幻影记录相同的键插入新行，则可以重用旧记录。因此，插入可能会变成对幻影位的修改，在大多数情况下，还会修改记录中其它一些除了键之外的字段。==<u>与删除时一样，键区间锁定只需要锁定键值，而不需要锁定插入新键的键区间</u>==。

虽然幻影记录通常与B-tree中的记录删除相关，但它们也可以帮助插入新键。将插入拆分为两步可以减少事务所需的锁。首先，在**latch**的保护下，用所需的键创建一个重幻记录，此步不需要锁。第二，用户事务根据需要锁定和修改新记录。如果用户事务失败并回滚，则保留幻影记录。第二步需要锁定键值，而不是插入新键的键值区间。

这个想法的另一个改进是，用将来可能插入的键创建多个幻影记录。如果将来插入的键完全可以预测，例如订单号和发票号，则这一点尤其有用。即使无法预测将要插入的键的精确值，这种幻影记录也可以有助于分离后续的插入，从而在后来的插入事务中实现更多的并发性。例如，键可以由多个字段组成，但只能对前导字段预测值，例如，每个订单中的订单号和行号。

> ==TODO：==Fig.4.6

图4.6说明了插入多个幻影记录。插入键值为11、12、13和14的有效记录后，下一个操作可能是插入键值为15、16、17等的记录。由于已经填写了这些键，在空间上预先分配了适当的空间，这样就可以提高这些插入的性能。用户事务节省了分配工作，只锁定键值，既不锁定键值之间的间隙，也不锁定现有最大键值与无穷大之间的间隙，这通常是此类**插入事务序列**的瓶颈。

最后，在有效的B-tree记录中，插入仅包含键、而不包含任何剩余字段的非常短的幻影记录是有益的。将这样的“幻影插槽”==**撒**==到有序记录序列（或间接数组中的槽）中可以实现页面内的有效地插入。在没有这种幻影插槽的页面中，插入需要移动所有条目的一半，比如间接数组中的插槽。在具有幻影插槽的页面中，插入的复杂性不是O (N)而是O (log N)[12]。例如，在每页有数千个小记录的二级索引中，插入需要在间接数组中移动十个而不是几千个元素，删除操作根本不会移动任何元素，只会留下一个幻影插槽，而页面重组则会留下大约10%或20%的幻影插槽。

> ==TODO：==Fig.4.7

图4.7是图3.3的细化，显示了两个差异。第一，间接数组中的元素包含键或键前缀。图中显示了字母，但真正实现时将使用最小规范化键，将它们解释为整数值。第二，其中一个是幻影插槽，因为它包含一个没有引用记录的键（“d”）。这个插槽可以参与二叉搜索和键区间锁定。它可能在页面重组期间被放在那，或者可能是快速删除记录的结果，而没有移动键“g”和“k”的两个槽。一旦存在，它就可以加速插入。例如，插入带有“e”键的新记录可以简单地修改当前包含“d”的槽。当然，这要求当前未锁定键“d”，或者锁管理器允许适当的调整。

- 幻影记录（也称为伪删除记录）通常用于减少删除期间的锁定需要，并简化删除的“撤消”。
- 幻影记录不影响查询结果，但参与键区间锁定。
- 可以在插入时或异步清理时，回收幻影记录或其空间，但前提是它未被锁定。
- 幻影记录也可以加速和简化插入。

### 4.3 键区间锁定

术语键值锁定和键值区间锁定通常可以交换使用。封锁整个键值区间，而不封锁键值的唯一原因就是保护事务不受其它事务插入语句的影响。例如，如果事务执行类似这样的SQL：`select count (*) from . . . where . . . between . . . and . . . ,`，也就是在某个索引列上进行范围查询，并且该查询运行在『可串行的事务隔离级别』，那么如果事务再次执行该查询，得到的结果和前次执行的结果应该一样。换言之，除了保护查询范围内的B-tree记录不被删除之外；事务获得并持有的『事务锁』也必须能阻止『在查询范围内、已有的键值之间』插入新的B-tree记录，也就是，键值区间封锁通过锁定已有键值之间的“空隙”，确保该“空隙”内没有出现的键值，（在事务完成之前（中止或是提交））一直不会出现。比『可串行化』弱的事务隔离级别，不会提供这样的保证，但很多应用开发人员并不能理解它们精确的语义，以及它们对应用程序正确性的有害影响。

键值区间锁定是谓词锁定[31]的一种特殊形式。主流产品既没有采用通用的谓词锁定，也没有采用较为实用的==<u>『precision locking』</u>==[76]。『键值区间封锁』通过B-tree『排序顺序中的区间』来定义它的谓词，区间的边界是B-tree中当前存在的键值，通常的形式是半开区间，这里的半开区间包括相邻的两键值之间的空隙，及其中某端的键值；『右键值锁定』较『左键值锁定』通用。『右键值锁定』要能锁定人为的+∞；『左键值锁定』则可以锁定null，即，假设null是B-tree排序顺序中可能出现的最小值。

最简单的键值区间锁定是将『键值和其相邻的区间』作为整体锁定。对『B-tree记录、记录的键值或是相邻键值之间的区间』任何形式的修改，包括修改记录的非键值字段、删除某个键值、在键值之间的空隙插入新键值等等，都需要『独占事务锁』。删除某个键值，除了要锁定该键值之外，还需要锁定与它（右边）相邻的键值，锁定相邻键值的原因是万一事务回滚，确保能重新插入删除的键值。

> ==TODO：==Fig.4.8

图4.8演示的是单个键值上的键值区间封锁可能保护的几个“对象”，作为示例的B-tree叶节点包含三个键值，在1170到1180之间，键值1174上的『事务锁』可能覆盖的范围，如箭头所示。第一个箭头演示的是传统的『右键值锁定』，即，『事务锁』锁定的是两个键值之间的“空隙”，以及“空隙”后的记录键值。==<u>第二个箭头显示『左键值锁定』</u>==，第三个箭头表明『事务锁』仅仅锁定键值自身，没有覆盖键值左右两边任何一边的空隙，所以在事务持续期间，这个『事务锁』不能阻止某个键值的出现，例如插入键值1176，因此不能保证可串行性。

要简短地讨论下第四个箭头所指示的『事务锁』，它用于补充『键值锁定』，可以在『不锁定已存在的键值』情况下，保证其它事务不能（在键值的“空隙”中）插入新键值。当一个事务像第四个箭头所示那样，锁定键值1174时，第二个事务可以更新『键值为1174』的记录，更具体地说，第二个事务不能更新记录的键值（即1174），但能更新记录的『非键值字段』，因此，在第一个事务释放其『事务锁』之前，第二个事务不能删除（键值为1174的）记录。另一方面，第二个事务可以更新记录的『幻影标志位』，比如，如果发现键值为1174的记录有效，第二个事务可以将其变为幻影记录，从而将其从后续查询的结果集中排除；反过来，第二个事务也可以将幻影记录变为有效记录，并更新其『非键值字段』，这就是在B-tree中实施逻辑插入。为了简化后面的讨论，图4.8少画了一个指示『事务锁』锁定范围的箭头，它可以锁定『被锁定键值』左边的范围。

键值区间封锁广泛用于商业系统中，ARIES/KVL（键值封锁）和ARIES/IM（索引管理）都是键值区间封锁的一种形式，两种封锁技术都不会锁定索引中的单个索引记录，ARIES/KVL锁定索引中唯一的键值，如果是『非唯一二级索引』，一把锁就能锁定某个键值的所有记录，及到其左边键值的开区间。==*『串行隔离级别』的事务向这样的开区间插入时，仍要请求（右边键值的）『事务锁』，即使只有瞬时持续时间*==。如果并发事务持有『相冲突的事务锁』，例如，某个读事务正在访问区间内的某个记录，那么插入要么失败，要么被延迟。在『读取记录的事务』和『插入不同键值的事务』之间，并不存在真正的冲突，只是（设计应用时）选择的隔离级别，使得它们好像有冲突一样。可能正是由于这种人为的冲突，许多数据库都运行在比『可串行化』弱的事务隔离级别上，并且很多软件厂商总是选择较弱的隔离级别作为缺省的隔离级别。

ARISE/IM中的『事务锁』锁定表中的某条记录，包括为该条记录建立的所有索引，以及每个索引中『索引记录左边』的开区间（称之为“data-only locking”，后续的DB2中是“type-1 indexes”）。在非唯一索引中，这个开区间左边的记录可能键值相同，但记录标志符不一样。在ARISE/IM中，如果是页级封锁，一把锁将会锁定数据页中的所有记录、它们的索引记录、索引键值对应的开区间。“修改结构的操作”需要获取一把专门针对索引树的『独占线程锁』，只读操作只在检查到页面的“结构修改位”被置位后，才会按共享模式请求这把『线程锁』。由于这两种方法非常复杂，又包含太多的细节，我们鼓励读者去看原始的论文，而不是依赖于像本文这样的二道贩子。但愿读者们读完此文后，可以更容易理解原始的ARIES论文。

微软SQL server的键值区间封锁基于Lomet的设计[85]，而Lomet的设计又基于ARIES/IM和ARIES/KVL [93, 97]。和ARIES一样，Lomet的方案也需要“瞬时锁”，即，锁持有的时间极其短；不同的则是需要一种新的锁模式：“插入锁”，仅仅应用于B-tree索引中两个键值之间的开区间。然而，在SQL Server公开的锁兼容矩阵中，“插入锁”和互斥锁太类似了，以至于不太清楚“插入锁”有什么用，为什么需要区分“插入锁”和互斥锁。最近的设计[48]即不用“瞬时锁”，也不用“插入锁”，但相比Lomet的方案，又能提供更高的并发性。

建立在层次封锁[58]基础上的键值区间封锁，能支持各种各样的锁粒度。在锁定细粒度的一个或多个资源之前，先用适当的意图锁封锁粗粒度的资源。典型的使用场景是：使用共享模式锁定整个要搜索的文件，再用互斥模式封锁要修改的少量记录。此时就需要用『IX模式的事务锁（意图获取互斥锁）』封锁整个文件，再用『互斥事务锁』封锁要修改的个别记录。这样在文件层次就能检查到冲突，具体地说，就是共享锁和IX锁之间的冲突。

> ==TODO==：Fig.4.9

图4.9显示的是层次封锁中，各类锁之间的兼容性矩阵。标记为a的字段表示这两类锁的不兼容，是由更新锁的不对称性引起的。这个兼容矩阵比传统的兼容矩阵更好，它加入了请求的锁和持有的锁组合后的模式，本文称之为聚合锁模式。比如，如果多个事务已经用IS锁将某个资源锁定（只有IS锁，没有其它类型的锁），那么聚合锁就是IS锁，基于此聚合锁，如果事务请求IX锁，就可直接授予之，而无需检查『前面事务所持有的、锁定该资源的』每一把IS锁，此外，新的聚合锁转换成IX锁。

从图4.9可以看到，两类意图锁总是兼容的，这是因为将在更细的粒度上检查真正的冲突。另外，意图锁和纯粹的读写锁之间的兼容性，和读写锁之间的兼容性完全一样；与『组合锁模式S+IX』兼容的锁，须得同时兼容共享锁和IX锁。

根据Gray和Reuter的书[59]，图4.9显示的是更新（U）锁，而非意图更新锁（IU和SIU），应该选择获取意图写锁(IX和SIX)来替代获取它们。粗粒度上的IX锁覆盖了细粒度上的更新锁。

在基于层次封锁的键值封锁中，粗粒度的封锁是锁定半开区间；细粒度的封锁要么锁定键值，要么锁定开区间。因此简单分层，就可以提供非常精确的封锁区间，以适合每个事务需要。这个设计的缺点是锁定键值（或是开区间）需要调用锁管理器两次：一次是使用意图锁封锁半开区间，一次是使用读写锁封锁键值。

由于『都是通过唯一的键值』来确定三个不同的锁（键值、开区间、以这两者组合而来的半开区间），所以在锁模式的数量和锁管理器的调用次数之间，可以做各种折衷。使用精心设计的锁模式，来描述『如何锁定半开区间、键值、开区间之间的组合』。因此，利用层次锁『封锁半开区间、键值、开区间』的系统，所需要的封锁开销，不会比那些只封锁半开区间的系统高。无需额外的运行时成本，这样的系统允许『分别锁定键值和开区间的不同事务』并发执行，也就是确保『不在开区间内插入新键值』的同时，允许事务更新与非键值无关的记录属性，这包括『指示该记录是否为幻影记录』这样的属性。因此，当另一个事务已锁定相邻的开区间时，逻辑插入或删除仍然可能。

具体地说，就是用S（共享）、X（互斥）、IS（意图共享）和IX（意图互斥）这几种模式来封锁半开区间，但不用SIX（共享+意图互斥）模式，这是因为只封锁两个资源，容易实现更为准确的锁模式；用S和X两种模式来封锁键值和开区间。两个资源（键值和开区间）上三种锁模式（S、X和N(没有锁)）的各种可能的组合，必须能被新（设计）的锁模式覆盖，意图锁（IX和IS）则以隐含的方式继续存在。比如，如果使用X模式封锁键值，则隐含表示用IX模式封锁半开区间；如果使用S模式封锁键值，X模式封锁开区间，那么半开区间上隐含的封锁模式是IX。使用两种锁模式（一个是封锁键值的锁模式，一个是封锁开区间的锁模式），来区分锁很容易。假设使用左键值封锁协议，SN锁表示『使用S模式的锁保护键值，且没有封锁键值右边的开区间』；NS锁则是没有封锁键值，但封锁了其右的开区间（S模式）。这个（新设计的）锁模式可以用于预防幻象，这正是可串行的事务隔离级别所要求的。

> ==TODO==：Fig.4.10

图4.10表示的是（这个新方案）的锁兼容矩阵，推导出这个矩阵很简单，只需分别检查第一个组件之间的兼容性和第二个组件之间的兼容性。例如，XS和NS兼容，是因为X和N兼容，而S和S也是兼容的。一个字符的锁（封锁半开区间）等价于分别是使用这个模式的锁封锁键值和开区间，但是，除非绝对必要，引入更多的锁模式没有好处。

图4.10也显示出某些情况，最终聚合后的锁模式，即不等于『先前持有的聚合锁』的模式，也不等于请求的锁模式。SN和NS组合成S模式，但更有趣的是，SN和NX不仅兼容，而且也不必定义特殊的聚合锁模式，完全是根据现有的规则推导而来。

如果二级索引中的索引记录不唯一，每个键值可能会关联多个记录，更有甚者，每个键值可能关联上千个记录,这是由于某个键值频繁使用，或是某些属性只有几个不同的键值。在非唯一索引索引中，键值封锁可能会锁定每个键值（因此也锁定了对应的整个记录集），或是锁定唯一的『键值和记录标记符』对。前者节省了每次查找所需的锁请求总量；后者则允许更新时有更高的并发。在前者的设计中，可以使用意图锁来锁定键值，从而获得高并发。根据设计细节，可能并不需要根据『二级索引中的记录标记符』单独锁定对应的记录，这是因为可能在遍历二级索引所属的表时，就已经锁定这些记录了。

除了传统的读写锁，或是共享和互斥锁外，其它的锁模式也被研究过。最有名的就是“增量”锁，增量锁使得事务可以并发增加和减少总和和总数，在明细表中几乎没有这样的并发操作，但是在汇总视图中，这类并发操作很可能成为瓶颈。在为物化视图定义的B-tree索引中，即使明细表的插入和删除影响了所有分组，并因此影响汇总记录，及汇总记录的索引，但『幻影记录、键值区间封锁和增量锁』的组合仍使得高并发成为可能。扩展键值区间封锁以支持增量锁，包括用增量锁封锁既有键值之间的区间，并不难。更多的细节可以在[51，55，79]中找到。

如果在与时间相关的属性上建立索引，那么过高的插入率将会导致B-tree的“右边缘”成为热点，使用右键值封锁，有两个解决方案。一个方案是请求“瞬时事务锁”，即，只检查能否锁定+∞（正无穷大），但并不持有，这个假设违反了『两阶段封锁协议』，但是如果『在页面上插入新键值』和『检查是否能锁定+∞』是在『同一个页面线程锁』保护下完成的话，系统仍能正常工作。另一个方案是依赖于系统事务插入幻影记录，用户事务再将这些幻影记录转换成有效的索引记录，这样用户事务之间就不会互相影响。系统事务修改数据库的逻辑内容时，不需要任何事务锁；随后的用户事务使用键值封锁，仅仅锁定要修改的B-tree索引记录。如果索引记录的插入键值是可以预测的，比如订单号，一个系统事务就可以插入多个幻影记录，因此，就可以为多个用户事务服务。

- 键区间封锁不但封锁键值，还封锁键值之间的区间。它以一种『即特殊又实用』的方式实现谓词锁，它们之间的不同体现在『设计的简单性』和『所支持的并发性』上。
- 为了满足事务的可串行性（即并发事务之间的真正隔离，等价于串行执行事务），需要封锁现有键值之间的区间，这等价于锁定不存在的新键值。

> ==TODO：==
>
> 1. 解释precision locking的含义，右键值锁定：（x,y]，左键值锁定：[x,y)
> 2. 封锁右键和封锁左键的区别

### 4.4 叶边界处的键区间锁定

传统的键值区间封锁中，另一个复杂性和低效率的来源是横跨两个相邻叶节点的区间锁。例如，如果『新插入的B-tree索引记录的』键值，在其插入的叶节点中最大，那么右键值封锁需要在后一页叶节点中找到最小的键值；左键值封锁也有同样的问题，不过是在键值为插入叶节点中最小时出现。为了能快速访问下一页叶节点，许多系统都在每个节点，或者至少是在叶节点中，包含一个指向下一页的指针。避免邻接指针的替代方案是在每一个B-tree节点中引入两个“防护键”,它们定义了在这个节点中，后续键值的插入范围，其中一个表示为闭区间，另一个表示为开区间，这取决于当父节点中的分隔键完全等于搜索键时，所采取的决定。

一开始，空的B-tree只有一个节点，该节点既是根节点，又是叶节点，使用特殊的“防护键值”来表示正负无穷大，其它所有的“防护键”和分裂叶节点时所确定的分隔键完全相同：当B-tree节点（叶节点，或是分支节点）因为溢出而分裂时，父节点内的分隔键，同样在分裂后的两个子节点中保留了一份，分别作为这两页“防护键”的上界和下界。

防护键不必总是有效的B-tree记录。具体地说就是，作为闭区间的防护键有时可能是有效的数据记录；但是另一个（表示开区间的）防护键总是无效（表现为幻影记录）。如果删除了作为防护键的有效记录，那么仍然要在该页叶节点中，以幻影记录的方式保留这条记录（的键值）。实际上，使用幻影记录只是一个实现技术上的选择，但和传统的幻影记录不同，不能因为插入新记录需要空闲空间，或着因为（背台运行的）清理工具，而移除『表现为幻影记录的防护键』。不过只要新插入的键值恰好等于防护键，作为闭区间的幻影防护键可以被再次转换为有效记录。

> ==TODO==：Fig.4.11

图4.11显示的是带有防护键的叶节点和内部非叶节点（这儿是根节点）。由于防护键定义了页内可能的键值范围，因此没有必要锁定相邻节点上的键值。由于新插入的键值恰好等于防护键，而将幻影防护键转换为有效记录时，不必使用键值区间封锁，只需要锁定插入的键值即可，这些因为插入事务（实际上）并没有新建记录，而只是修改一条已存在的B-tree记录而已。

- 老旧的设计封锁两个键值之间的区间时，如果两个键值分别存储在相邻的两个叶节点上，无论其中的一个叶节点在『本次查询或更新中』是否会被用到，都需要同时访问这两个相邻叶节点。
- 防护键是『分裂叶节点时创建的』分割键的一份拷贝。在每个叶节点中，一个防护键（比如上界）总是幻影记录，而另一个防护键可以是幻影记录，也可能是有效记录。使用防护键的键值区间封锁，不必访问相邻的叶节点。

### 4.5 分隔键的键区间锁定

在大多数商业数据库系统中，锁的粒度是一个完整的索引、一个索引叶（叶节点）或一个单独的键（如上所述，具有键值的**子层次结构**和键之间的**开区间**）。锁定物理页和逻辑键区间可能会令人困惑，特别是在必须考虑页分裂、碎片整理等时。另一种模型依赖<u>在叶节点直接上层的B-tree节点中的分隔键</u>的**键区间锁定**[48]。这与在B-tree叶节点锁定**fence键**不同，就算是使用相同的键值。每个此类锁的范围类似于页锁，但分隔键上的锁是**谓词锁**，其方式与B-tree叶节点中的键区间锁相同。==<u>叶节点分裂期间的锁管理可以依赖于 B^link^-tree的中间状态，或者通过将锁从一个分隔键复制到新建的分隔键</u>==。

但是，非常大的数据库表及其索引可能需要数百万个叶页，这迫使许多事务获取数千个锁，或锁定比它们访问的数据要多的多的数据。虽然还没有在商业系统中使用，但是已经提出了==**索引锁**==和==**页锁**==之间具有中间级别的锁层次结构。

其中一个**方案**[48]利用B-tree结构，将叶节点上一层的B-tree分隔键上的**键区间锁定**添加到叶节点键上的**键区间锁定**。在该方案中，锁标识符不仅包括键值，还包括B-tree索引中的ç（例如，层0是叶节点）。这种技术可以自然地适应键的倾斜分布，就像分隔键集也可以适应键的实际分布一样。

另一个方案[48侧重于B-tree的键，从复合键（即多列键）如“姓氏，名字”中派生出锁的粒度。这种方法的优点是它承诺在查询和数据库应用程序中匹配谓词，以便它可以最小化所需锁的数量。Tandem的“通用锁定”是一种严格的形式，使用键中固定数量的前导字节来定义键区间锁定的范围^5^。

> 5. Saracco和Bontempo [113]描述了Tandem的通用锁定如下：“**除了能够锁定行或表分区之外，NonStop SQL/MP还支持<u>键顺序表的通用锁</u>的概念。 通用锁通常会影响某个键范围内的多个行。受影响的行数可能小于、等于或大于单页。建表时，数据库设计者可以指定要应用于主键的“锁定长度”参数。 此参数确定表的最佳锁定粒度。假设，一个保险策略表以10个字符的ID列为主键。 如果为锁定长度参数设置为“3”，系统锁定的所有行是：其ID列的前三个字节匹配查询中用户定义的搜索参数。**”注意，Gray和Reuter[1993]将键区间锁定解释为锁定键的前缀，不一定是整个键。

**大范围锁定键值区间**的两个方案需要制定许多细节，在第一次出现工业强度的实现时，才会显现出其中许多细节。 该方法的变体[4]已被用于XML存储中，其中节点标识符遵循分层方案，使得祖先的标识符始终是其后代的前缀。

- 大型索引需要在锁定键值和锁定整个索引之间的**中等粒度锁**。
- 除了（或代替）锁定键值之外，传统设计还包括叶节点上的锁。索引中的页节点数量，以及查询中页节点的锁定数量，可能远远超过锁管理器升级到更粗粒度锁的阈值（通常是几千）。
- 或者，**键区间锁定**可以应用于B-tree中某些或所有分支节点中的分隔键。该设计将传统的分层锁与B-tree及其层次结构相适应。

### 4.6 B^link^树

在B-tree的原始设计中，溢出节点分裂至少更新三个节点：溢出叶节点，新分配的叶节点及其父节点。 在最坏的情况下，必须分裂多个祖先。保护所有受影响节点上、不完整更新的数据结构，不被其他线程或事务读取或更新需要使用**latch**。单个线程锁定B-tree的大量节点，显然限制了并发性，可伸缩性以及系统性能。这就需要==**放松什么是正确B-tree的定义**==，而不是弱化不同线程（之间的同步），从而冒着B-tree不一致的风险。一个这样的设计用两个独立的步骤分裂节点，即先分裂节点，然后在父节点中发布一个新的分隔键。第一步之后，溢出节点需要一个分隔符键和一个指向其右邻居的指针，因此称为B^link^-tree [81]。

在第二步之前，尚未在分裂节点的父节点中引用右邻居。换句话说，父节点中==**一个键值范围及其关联的子指针**==实际上是指向两个子节点。沿着该指针，从根到叶搜索必须首先将所寻找的键值与子节点的上界进行比较，如果所寻找的键值更大，则继续到其右邻居搜索。为了确保高效的对数复杂度的搜索行为，这种状态只是暂时的，一有机会就恢复。

第一步，为分裂的节点定义分隔键，创建新的右邻居节点，确保两个节点中的**fence键**都正确，并在旧节点中保留新节点**fence键**的上界。在B-tree中进行正确搜索不需要最后一个操作，但它可以对B-tree进行有效的一致性检查，即使某些节点处于这种瞬态状态。这种瞬态下，旧节点可以称为新节点的“养父节点”。

第二步，独自在父节点中发布分隔键，可作为未来根到叶遍历的一个副作用，应尽快发生；但可能会延迟到系统重启，甚至崩溃及其恢复之后，但不会丢失数据，或导致磁盘上出现不一致的数据结构（==<u>有关允许的状态和不变式的更多详细信息，请参见图6.11</u>==）。

B^link^-tree的优点是，新节点的分配及将其最初引入B-tree是一个局部步骤，只影响一个先前存在的节点，只需要在溢出节点上使用**latch**。缺点是，在瞬态下搜索效率可能会低一些，需要一种解决方案，防止在频繁插入期间，相邻节点列表可能过长的问题，并且验证B-tree结构的一致性更为复杂，效率也许更低。

> ==TODO：==Fig.4.12

图4.12说明了在标准B-tree中不可能的状态，但在B^link^-tree中是正确的中间状态。这里的“正确”意味着搜索和更新算法必须能处理此状态，并且验证磁盘数据结构正确性的数据库实用工具不得报告错误。在原始状态中，父节点有三个子节点。请注意，这三个子节点可能是叶子或分支节点，父节点可能是B-tree的根节点或分支节点。第一步是分裂子节点，产生图4.12所示的中间状态。第二步稍后将第四个子指针放入父节点并放弃邻居指针，除非是特定的，需要邻居指针的B-tree实现。注意与2-3树中三元节点的相似性，如图2.2所示。

在大多数情况下，在父节点（上面的第二步）中发布分隔键可以是一个==<u>非常快的系统事务</u>==，在下一次从根到叶的遍历中完成。不需要将此线程作为更新事务的一部分，因为B-tree中任何结构的更改都将是系统事务的一部分，而不是用户事务。当线程同时在父节点和子节点上持有**latch**时，它可以检查是否存在尚未发布的分隔键。如果是，它将其**latch**升级为独占**latch**，在父节点中**分配一条新数据项**，并将分隔键从子节点移动到父节点。**<u>如果</u>**另一个线程持有共享**latch**，则放弃该操作并将其留给后续根到叶的搜索。**<u>如果</u>**父节点不能多容纳一个分隔键，则会分配、填充新的分裂节点，并将其链接到父节点中。分裂父节点应该是一个单独的系统事务。**<u>如果</u>**根到叶搜索发现根节点具有链接的溢出节点，则树应该增长一层。**<u>如果</u>**不能立即获取所需的任何 **latch**，则可能会中止系统事务，并将其留给稍后的B-tree遍历，以将分隔键发布到父节点中。

如果（不太可能地情况），在父节点中发布分隔符键之前必须再次拆分节点，则多个溢出节点可以形成链接列表。通过限制父节点对应的子节点的分裂操作，可以防止由于多次拆分而导致的长链接列表。这些操作和更多细节在最近的一篇论文中描述[73]。

==<u>可以反转B^link^-tree的拆分过程</u>==，以便能够删除B-tree节点[88]。第一步创建邻居指针并从父节点移除子指针，然后第二步将删除节点的其它记录合并到邻居节点。B^link^-tree的瞬态状态甚至可能对兄弟节点之间的负载平衡和B-tree的碎片整理有用，尽管这种想法尚未在研究原型或工业实现中尝试过。 

- B^link^-tree 放松了严格的B-tree结构，以实现更多的并发性。 拆分节点和在父节点中发布新的分隔键是两个独立的步骤。
- 每个步骤都可以是一个系统事务，提交之后，其更改对其他线程和其他事务可见。
- 在这两个步骤之间的瞬态中，旧节点是新节点的“养父”。 瞬态应该是短暂的，但如果第二步被延迟（例如，由于并发冲突），则可能持续存在。
- B^link^-trees 及其瞬态可能对B-tree中其他结构的变化有用，例如，删除节点（合并两个节点的键范围）和两个节点之间的负载平衡（替换分隔键）。

### 4.7 获取事务锁期间，如何操作线程锁（ Latches During Lock Acquisition ）

如果**事务锁**是定义在B-tree的实际键值上，则必须小心管理**线程锁**。具体地说，当事务试图获取一个键区间的事务锁时，它的线程必须在缓冲池中的数据结构上持有线程锁，这样另一个线程就不能删除该键值。另一方面，如果不能立即获取**事务锁**，则在事务等待时线程不应持有**线程锁**。事实上，这个语句可能更为通用：线程在持有线程锁时决不能等待，否则，多个线程可能会死锁。回想一下，死锁检测和解决方案通常只提供给事务锁，而不提供给线程锁。

有几种设计可以解决这个潜在的问题。在一个解决方案中，锁管理器调用在检测到冲突时，只对事务锁请求进行排队，然后返回。这允许线程在第二次调用锁管理器，并等待事务锁变为可用之前释放相应的线程锁；第一次调用仅仅使事务锁请求失败是不够的。在将事务锁请求插入锁管理器的数据结构之前，需要使用线程锁对缓冲池中的数据结构进行锁定，以确保键值的存在。

另一个解决方案将函数和适当的函数参数传递给锁管理器，以便在等待之前调用。此回调函数可以释放缓冲池中数据结构上的线程锁，在等待结束后和再次获取事务锁之时重新获取线程锁。==<u>无论那种方案，请求事务锁期间的操作序列不仅需要指示成功与失败，还需要指示即时成功与延迟成功</u>==。

当等待键值上的事务锁时，事务并没持有缓冲池中数据结构的线程锁，其他事务可能会更改B-tree的结构，即通过分裂、合并、负载平衡或页面移动，例如B-tree碎片整理，RAID或闪存上的写优化B-tree[44]。**因此在获取键值的事务锁之后，事务必须重复从根到叶搜索键值。**为了最小化重复搜索的成本，可以在等待之前保留根到叶路径上页面的日志序列号，并在等待之后进行验证。或者可以使用（结构修改的）计数器快速确定B-tree结构是否发生了变化[88]。这些计数器可以是系统状态的一部分，即不是数据库状态的一部分，因此在系统崩溃后不需要恢复其先前的值。

- 获取键值的事务锁时，必须持有数据页的线程锁，以防止键值被删除，但在等待事务锁时，不能持有数据页上的线程锁。

- 需要回调或重复调用锁管理器的解决方案，一个用于等待获取事务锁，另一个用于将锁插入等待队列。

  

### 4.8 蟹行协议（Latch Coupling）

根到叶遍历期间，从一个B-tree节点前进到它的某个子节点时，在读取指针值（子节点的页面标识符）和访问子节点之间存在一个短暂的漏洞窗口。在最坏的情况下，另一个线程会在这段时间内从B-tree中删除子节点，甚至可能在另一个B-tree中开始开始使用该节点。如果子节点存在于缓冲池中，则概率很低，但不能忽略。如果忽略或未正确实现，则很难将此漏洞确定为数据库损坏的原因。如果缓冲池中不存在子节点，且需要I/O，则需要考虑其他因素，这将在下一小节中讨论。

一种称为蟹行协议（Latch Coupling）的技术避免了这个问题。从根到叶搜索时，保留父节点上的**线程锁**，从而保护节点不受更新的影响，直到它获得子节点上的**线程锁**为止。一旦子节点被定位、固定、并使用线程锁在缓冲池中锁定之，就会释放父页面上的线程锁。如果子节点在缓冲池中随时可用，则父节点和子节点上的线程锁仅在很短的时间内重叠。

蟹行协议（Latch Coupling）发明于B-tree的历史早期[9]。对于只读查询，共享模式下，一次最多需要使用事务锁（或线程锁）锁定两个节点。==<u>在最初的插入设计中，独占锁沿着根到叶路径保留在所有节点上，直到找到一个节点有足够的空闲空间，以允许分裂子节点并发布分隔键</u>==。不幸的是，可变大小的记录和键可能会导致使用非常保守的决策。相反，新设计依赖于B^link^-tree（在可以发布分隔键之前的临时邻居指针），或重复的从根到叶的遍历。初始的根到叶遍历，即使预期操作将通过插入或删除来修改叶节点，也在根节点和分支节点上使用共享**线程锁**。

依赖于相邻指针以实现高效的游标，扫描和键区间锁定的系统（即，没有利用**fence键**），在邻居节点之间也采用蟹行协议（Latch Coupling）。在这些系统中，多个线程可能试图从不同的方向使用**线程锁**锁定叶节点，这可能导致死锁。回想一下，线程锁通常不支持死锁避免或检测。因此，线程锁获取必须包括**快速失败的无等待**模式，并且B-tree代码必须处理获取线程锁失败的情况。

大多数根到叶遍历一次最多保持两个B-tree节点上线程锁，即父子节点。分裂操作需要保存三个B-tree节点的线程锁，其中一个用于新分配的节点。此外，还需要使用**线程锁**锁定空闲空间信息。在B^link^-tree中，分裂操作一次只需要两个线程锁。即使将分隔符键和指针从子节点移动到父节点的最终操作也只需要两个线程锁；不需要使用**线程锁**锁定新节点。另一方面，B^link^-tree中完整的分裂序列，需要有两个独占线程锁的周期，即使最终操作可延迟到合适的线程锁可用为止。

- 在从一个B-tree节点导航到另一个节点的过程中，指针必须保持有效。通常的实现会持有源的线程锁，直到获取目标的线程锁为止。
- 如果需要I/O，应该释放线程锁。可能需要从根节点开始重复遍历B-tree。
- 即使在分裂节点和发布分隔符键时，B^link^-tree一次最多获取两个节点的线程锁。

### 4.9 物理逻辑日志

### 4.10 Non-logged Page Operations

Another logging optimization pertains to structural B-tree operations, i.e., splitting a node, merging neighboring nodes, and balancing the load among neighboring nodes. As for in-page compaction, detailed logging can be avoided because those operations do not change the contents of the B-tree, only its representation. Differently from in-page compaction, however, there are multiple pages involved in these operations and the contents of individual pages indeed changes.

The operations considered are actually reflected in the recovery log; in that sense, the commonly used term “non-logged” is not literally accurate. A better descriptive name might be “allocation-only logging” instead. The savings are nonetheless substantial. For example, in strict physical logging, splitting a node of 8 KB might generate 24 KB of log volume plus log record headers, a few short log records for page allocation, and transaction commit, whereas an optimized implementation might required only these few short log records.

The key insight is that the old page contents, e.g., the full page prior to the split, can be employed to ensure recoverability of both pages after the split. Thus, the old contents must be protected against over-writing until the moved contents is safely written. For example, splitting a full page proceeds in multiple steps after the page is loaded into the buffer pool and found to require a split:

1. a new page is allocated on disk and this allocation is logged, 
2. a new page frame for this new disk page is allocated in the buffer pool, 
3. half the page contents is moved to the new page within the buffer pool; this movement is logged with a short log record that does not include the contents of the moved records but probably includes the record count, 
4. the new page is written to the data store, and 
5. the old page is written to the data store with only half its original content remaining, overwriting the old page contents and thus losing the half moved to the other page. 

The careful write ordering in steps 4 and 5 is crucial. This list of actions does not include posting a new separator key in the parent node of the full node and its new sibling. Further optimizations are possible, in particular for Blink-trees [73]. The log records in the list above could be combined into a single log record in order to save space for record headers. The crucial aspect of the above list is that the last action must not be attempted until the prior one is complete. The delay between the first three actions and these last two actions can be arbitrarily long without putting reliability or recoverability in danger.

Variants of this technique also apply to other structural B-tree operations, in particular merging neighboring nodes, balancing the load among neighboring nodes, and moving entries in neighboring leaves or branch nodes in order to re-establish the desired fraction of free space for the optimal tradeoffbetween fast scans and fast future insertions. In all these cases, allocation-only logging as described above can save most of the log volume required in physical logging. More details on non-logged page operations are discussed in Section 6.6.

- “Non-logged” should be taken to mean “without logging page contents.” Another name is “allocation-only logging” or “minimal logging.” 
- When moving records from one page to another (during split, load balancing, or defragmentation), the old page can serve as backup. It must be protected until the destination page is saved on storage. 

### 4.11 Non-logged Index Creation

The term “non-logged index creation” seems to be commonly used although it is not entirely accurate. Changes in the database catalogs and in the free space management information are logged. The content of B-tree pages, however, is not logged. Thus, non-logged index creation saves perhaps 99% of the log volume compared to logged index creation.

All newly allocated B-tree pages, both leaves and branch nodes, are forced from the buffer pool to permanent storage in the database before committing the operation. Images of the B-tree nodes may, of course, remain in the buffer pool, depending on available space and the replacement policy in the buffer pool. Page allocation on disk is optimized to permit large sequential writes while writing the B-tree initially as well as large sequential reads during future index scans.

> ==TODO：==Fig.4.15

Figure 4.15 compares the log volume in logged and non-logged index creation. The voluminous operations, in particular individual record insertions or full B-tree pages, are not logged. For example, instead of millions of records, only thousands of page allocations are logged. Commit processing is slow if pages have been allowed to linger in the buffer pool during load processing. But just as table scans interact badly with LRU replacement in a buffer pool, pages filled during load processing should be ejected from the buffer pool as soon as possible.

Recovery of non-logged index creation requires precise repetition of the original index creation, in particular is space allocation operations, because subsequent user transactions and their log records may refer to specific keys in specific database pages, e.g., during row deletion. When those transactions are recovered, they must find those keys in those pages. Thus, node splits and allocation of database pages during recovery must precisely repeat the original execution

- Since indexes can be very large, logging the entire contents of a new index can exceed the available log space. Most systems have facilities for non-logged creation of secondary indexes. 
- Upon completion, the new index is forced to storage. 
- A backup of the transaction log must include the new index; otherwise, subsequent updates to the new index cannot be guaranteed even if included in the transaction log and in a log backup. 

### 4.12 Online Index Operations

The other important optimization for index creation is online index creation. Without online index creation, other transactions may be able to query the table based on pre-existing indexes; with online index creation, concurrent transactions may also update the table, including insertions and deletions, with the updates correctly applied to the index before index creation commits.

The traditional techniques described here are sufficient for small updates but it remains unadvisable to perform bulk insertions or deletion while concurrently modifying the physical database design with index creation and removal. There are two principal designs: either the concurrent updates are applied to the structure still being built or these updates are captured elsewhere and applied after the main index creation activity is complete. These designs have been called the “no side file” and “side file” [98]. The recovery log may serve as the “side file.” 

Srinivasan and Carey [119] divide online algorithms for index creation further, specifically the “side file” approach. In their comparison study, all concurrent updates are captured in a list or in an index. They do not consider capturing updates in the recovery log or in the target index (the “no side file” approach). Their various algorithms permit concurrent updates throughout the index creation or only during its scan phase. Some of their algorithms sort the list of concurrent updates or even merge it with the candidate index entries scanned and sorted by the index builder. Their overall recommendation is to use a list of concurrent updates (a side file) and to merge it with the candidate index entries of the index builder.

> ==TODO：==Fig.4.16

Figure 4.16 illustrates the data flow for online index creation with and without “side file.” The upper operation starts with creating an empty side file (unless the recovery log serves as side file). Concurrent transactions buffer their updates there, and the entire contents of the side file is propagated after the scanning, sorting, and B-tree loading are complete. The lower operation starts with creating the new index, albeit entirely empty at this time. Concurrent transactions capture both insertions and deletions into the new index, even before and during B-tree loading.

The “side file” design lets the index creation proceed without regard for concurrent updates. This index creation process ought to build the initial index as fast as an oﬄine index creation. The final “catch up” phase based on the “side file” requires either quiescent concurrent update activity or a race between capturing updates and applying them to the new index. Some systems perform a fixed number of catch-up phases, with the first catch-up phase applying updates captured during index creation, with the second catch-up phase applying updates captured during the first catch-up phase, and with the final catch-up phase applying the remaining updates and preventing new ones. 

The “no side file” design requires that the future index be created empty at the start, concurrent updates modify the future index, and the index creation process work around records in the future index inserted by concurrent update transactions. One concern is that the index creation process may not achieve write bandwidth similar to an oﬄine index creation. Another concern is that concurrent update transactions may need to delete a key in a key range not yet inserted by the index creation process. For example, the index creation may still be sorting records to be inserted into the new index.

Such deletions can be represented by a negative or “anti-matter” record. When the index creation process encounters an anti-matter record, the corresponding record is suppressed and not inserted into the new index. At that time, the anti-matter record has served its function and is removed from the B-tree. When the index creation process has inserted all its records, all anti-matter records must have been removed from the B-tree index. 

An anti-matter record is quite different from a ghost record. A ghost record represents a completed deletion, whereas an anti-matter record represents an incomplete deletion. Put in another way, an anti-matter record indicates that the index creation process must suppress a seemingly valid record. If one were to give weight to records, a valid record would have weight +1, a ghost record would have weight 0, and an anti-matter record would have weight *−*1.

It is possible that a second concurrent transaction inserts a key previously deleted by means of leaving an anti-matter record. In that case, a valid record with a suppression marker is required. The suppression marker indicates that the first transaction performed a deletion; the remainder of the valid record contains the information inserted by the second transaction into the database. A third concurrent transaction may delete this key again. Thus, the suppression marker and the ghost record are entirely orthogonal, except that a ghost record with a suppression marker must not be removed like other ghost records because that would lose the suppression information.

> ==TODO：==Fig.4.17

Figure 4.17 illustrates use of ghost bit and anti-matter bit during online index creation without side-file. Keys 47 and 11 are both updated in the index before the index creation process loads index entries with those key values. This bulk load is shown in the last two entries of Figure 4.17. The history of key value 47 starts with an insertion; thus, it never has the anti-matter bit set. The history of key value 11 starts with a deletion, which necessarily must refer to a future index entry to be loaded by the index creation process; thus, this key value retains its anti-matter bit until it is canceled against a record in the load stream. The final result for key value 11 can be an invalid (ghost) record or no record at all.

In materialized summary (“group by”) views, however, ghost marker and suppression marker can be unified into a single counter that serves a role similar to a reference count [55]. In other words, if its reference count is zero, the summary record is a ghost record; if its reference count is negative, the summary record implies suppression semantics during an online index creation. In non-unique indexes with a list of references for each unique key value, an anti-matter bit is required for individual pairs of key value and reference. The count of references for a unique key value can be used similar to a ghost bit, i.e., a key value can be removed if and only if the count is zero.

 Maintenance of indexes whose validity is in doubt applies not only to online index creation but also to index removal, i.e., dropping an index from a database, with two additional considerations. First, if index removal occurs within a larger transaction, concurrent trans-actions must continue standard index maintenance. This is required as long as the transaction including the index removal could still be aborted. Second, the actual de-allocation of database pages can be asynchronous. After the B-tee removal has been committed, updates by concurrent transaction must stop. At that time, an asynchronous utility may scan over the entire B-tree structure and inserts pages into the data structure with free space information. This process might be broken into multiple steps that may occur concurrently or with pauses in between steps.

Finally, online index creation and removal as described above can easily be perceived by database users as merely the first step. The techniques above require one or two short quiescent periods of time at beginning and end. Exclusive locks are required on the appropriate database catalogs for the table or index. Depending on the application, its transaction sizes and its response time requirements, these quiescent periods may be painfully disruptive. An implementation of “fully online” index operations probably requires multi-value concurrency control for the database catalogs and the cache of pre-compiled query execution plans. No such implementation has been described in the literature. 

- Online index operations permit updates by concurrent trans-actions while future index entries are extracted, sorted, and inserted into the new index. Most implementations lock the affected table and its schema while the new index is inserted in the database catalogs and during final transaction commit. 
- Updates by concurrent transactions may be applied to the new index immediately (“no side file”) or after initial index creation is complete (“side file”). The former requires “anti-matter” records to reflect that the history of a key value in an index started with a deletion; the latter requires “catch-up” operations based on a log of the updates. 

### 4.13 事务隔离级别

### 4.14 小结

In summary, necessity has been spawning many inventions that improve concurrency control, logging, and recovery performance for databases based on B-tree indexes. The separation of locking and latching, of database contents and in-memory data structures, is as important as key range locking aided by ghost records during deletion and possibly also insertion. Reducing log volume during large index utilities, in particular non-logged (or allocation-only logged) index creation, prevents the need for log space almost as large as the database but it introduces the need to force dirty pages from the buffer pool. Finally, weak transaction isolation levels might seem like a good idea for increased concurrency but they can introduce wrong query results and, when used in updates that compute the change from the database, wrong updates to the database.

Perhaps the most urgently needed future direction is simplification. Functionality and code for concurrency control and recovery are too complex to design, implement, test, debug, tune, explain, and maintain. Elimination of special cases without a severe drop in performance or scalability would be welcome to all database development and test teams.